{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuel prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMP3O2jRHgaD1FeckmMCAeo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushal-h/Deep-Learning-Implementations/blob/master/Basic%20Regression/Fuel_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71BdpSY_UyZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "21f63205-96c8-485e-e391-772406e91d50"
      },
      "source": [
        "\"\"\"\n",
        "@Author: Kushal H\n",
        "\n",
        "Basic regression\n",
        "\"\"\"\n",
        "#importing library \n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaQYAFZ1Ws_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "465099c7-d0fa-4a10-8565-a83102b24c08"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDMzk10iWvxx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ed35f4e4-e17d-42f5-eb0f-bd5a22b5040c"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-695959b7-6aa7-4fe7-8dbc-c7d810ef6246\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-695959b7-6aa7-4fe7-8dbc-c7d810ef6246\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"kushalh\",\"key\":\"0826513800713de0884dd895db3f090c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cyQBEFoXDhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "096bbec5-7c84-4419-b489-8a899bb3797c"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh26mgV-XSc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dyFSAAhXUnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX_8oquTXYNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a6a28a5-6c8c-41f8-fe1d-60e0bd1ce407"
      },
      "source": [
        "! kaggle datasets download -d uciml/autompg-dataset\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autompg-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG19iUsCXaDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "acff6105-db47-4236-b69b-f476966e1bd1"
      },
      "source": [
        "!unzip /content/autompg-dataset.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/autompg-dataset.zip\n",
            "replace auto-mpg.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSD6ysmKXez4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/auto-mpg.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm5WYI6LXwEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bcb80aa8-6fad-47b3-9347-9aba3b4e4c9d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ... model year  origin                   car name\n",
              "0  18.0          8         307.0  ...         70       1  chevrolet chevelle malibu\n",
              "1  15.0          8         350.0  ...         70       1          buick skylark 320\n",
              "2  18.0          8         318.0  ...         70       1         plymouth satellite\n",
              "3  16.0          8         304.0  ...         70       1              amc rebel sst\n",
              "4  17.0          8         302.0  ...         70       1                ford torino\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwCUsoWoXyyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = dataset.columns"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xQ6PCswTbDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eb39e61a-d908-485c-fcf1-9f351b225099"
      },
      "source": [
        "column_names\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
              "       'acceleration', 'model year', 'origin', 'car name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5htu_2X-JO",
        "colab_type": "text"
      },
      "source": [
        "Clean the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8swJJbmX5DT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "dd8c7177-2df5-4fd1-b620-49482df74c2c"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      0\n",
              "weight          0\n",
              "acceleration    0\n",
              "model year      0\n",
              "origin          0\n",
              "car name        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf9FEnrrYGcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "739e5253-ad3b-4104-9da7-6da923e8ab55"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    398 non-null    object \n",
            " 4   weight        398 non-null    int64  \n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            " 8   car name      398 non-null    object \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 28.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-oCgb2mYXbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "3fb0a5ee-0b81-491c-de0e-043d06583549"
      },
      "source": [
        "dataset['horsepower']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      130\n",
              "1      165\n",
              "2      150\n",
              "3      150\n",
              "4      140\n",
              "      ... \n",
              "393     86\n",
              "394     52\n",
              "395     84\n",
              "396     79\n",
              "397     82\n",
              "Name: horsepower, Length: 398, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxgItFelYjQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a477d91-3b5b-4494-d4a7-2a5f8c428843"
      },
      "source": [
        "dataset['car name'].unique()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['chevrolet chevelle malibu', 'buick skylark 320',\n",
              "       'plymouth satellite', 'amc rebel sst', 'ford torino',\n",
              "       'ford galaxie 500', 'chevrolet impala', 'plymouth fury iii',\n",
              "       'pontiac catalina', 'amc ambassador dpl', 'dodge challenger se',\n",
              "       \"plymouth 'cuda 340\", 'chevrolet monte carlo',\n",
              "       'buick estate wagon (sw)', 'toyota corona mark ii',\n",
              "       'plymouth duster', 'amc hornet', 'ford maverick', 'datsun pl510',\n",
              "       'volkswagen 1131 deluxe sedan', 'peugeot 504', 'audi 100 ls',\n",
              "       'saab 99e', 'bmw 2002', 'amc gremlin', 'ford f250', 'chevy c20',\n",
              "       'dodge d200', 'hi 1200d', 'chevrolet vega 2300', 'toyota corona',\n",
              "       'ford pinto', 'plymouth satellite custom', 'ford torino 500',\n",
              "       'amc matador', 'pontiac catalina brougham', 'dodge monaco (sw)',\n",
              "       'ford country squire (sw)', 'pontiac safari (sw)',\n",
              "       'amc hornet sportabout (sw)', 'chevrolet vega (sw)',\n",
              "       'pontiac firebird', 'ford mustang', 'mercury capri 2000',\n",
              "       'opel 1900', 'peugeot 304', 'fiat 124b', 'toyota corolla 1200',\n",
              "       'datsun 1200', 'volkswagen model 111', 'plymouth cricket',\n",
              "       'toyota corona hardtop', 'dodge colt hardtop', 'volkswagen type 3',\n",
              "       'chevrolet vega', 'ford pinto runabout', 'amc ambassador sst',\n",
              "       'mercury marquis', 'buick lesabre custom',\n",
              "       'oldsmobile delta 88 royale', 'chrysler newport royal',\n",
              "       'mazda rx2 coupe', 'amc matador (sw)',\n",
              "       'chevrolet chevelle concours (sw)', 'ford gran torino (sw)',\n",
              "       'plymouth satellite custom (sw)', 'volvo 145e (sw)',\n",
              "       'volkswagen 411 (sw)', 'peugeot 504 (sw)', 'renault 12 (sw)',\n",
              "       'ford pinto (sw)', 'datsun 510 (sw)',\n",
              "       'toyouta corona mark ii (sw)', 'dodge colt (sw)',\n",
              "       'toyota corolla 1600 (sw)', 'buick century 350',\n",
              "       'chevrolet malibu', 'ford gran torino', 'dodge coronet custom',\n",
              "       'mercury marquis brougham', 'chevrolet caprice classic',\n",
              "       'ford ltd', 'plymouth fury gran sedan',\n",
              "       'chrysler new yorker brougham', 'buick electra 225 custom',\n",
              "       'amc ambassador brougham', 'plymouth valiant',\n",
              "       'chevrolet nova custom', 'volkswagen super beetle', 'ford country',\n",
              "       'plymouth custom suburb', 'oldsmobile vista cruiser',\n",
              "       'toyota carina', 'datsun 610', 'maxda rx3', 'mercury capri v6',\n",
              "       'fiat 124 sport coupe', 'chevrolet monte carlo s',\n",
              "       'pontiac grand prix', 'fiat 128', 'opel manta', 'audi 100ls',\n",
              "       'volvo 144ea', 'dodge dart custom', 'saab 99le', 'toyota mark ii',\n",
              "       'oldsmobile omega', 'chevrolet nova', 'datsun b210',\n",
              "       'chevrolet chevelle malibu classic', 'plymouth satellite sebring',\n",
              "       'buick century luxus (sw)', 'dodge coronet custom (sw)',\n",
              "       'audi fox', 'volkswagen dasher', 'datsun 710', 'dodge colt',\n",
              "       'fiat 124 tc', 'honda civic', 'subaru', 'fiat x1.9',\n",
              "       'plymouth valiant custom', 'mercury monarch', 'chevrolet bel air',\n",
              "       'plymouth grand fury', 'buick century',\n",
              "       'chevroelt chevelle malibu', 'plymouth fury', 'buick skyhawk',\n",
              "       'chevrolet monza 2+2', 'ford mustang ii', 'toyota corolla',\n",
              "       'pontiac astro', 'volkswagen rabbit', 'amc pacer', 'volvo 244dl',\n",
              "       'honda civic cvcc', 'fiat 131', 'capri ii', 'renault 12tl',\n",
              "       'dodge coronet brougham', 'chevrolet chevette', 'chevrolet woody',\n",
              "       'vw rabbit', 'dodge aspen se', 'ford granada ghia',\n",
              "       'pontiac ventura sj', 'amc pacer d/l', 'datsun b-210', 'volvo 245',\n",
              "       'plymouth volare premier v8', 'mercedes-benz 280s',\n",
              "       'cadillac seville', 'chevy c10', 'ford f108', 'dodge d100',\n",
              "       'honda accord cvcc', 'buick opel isuzu deluxe', 'renault 5 gtl',\n",
              "       'plymouth arrow gs', 'datsun f-10 hatchback',\n",
              "       'oldsmobile cutlass supreme', 'dodge monaco brougham',\n",
              "       'mercury cougar brougham', 'chevrolet concours', 'buick skylark',\n",
              "       'plymouth volare custom', 'ford granada', 'pontiac grand prix lj',\n",
              "       'chevrolet monte carlo landau', 'chrysler cordoba',\n",
              "       'ford thunderbird', 'volkswagen rabbit custom',\n",
              "       'pontiac sunbird coupe', 'toyota corolla liftback',\n",
              "       'ford mustang ii 2+2', 'dodge colt m/m', 'subaru dl', 'datsun 810',\n",
              "       'bmw 320i', 'mazda rx-4', 'volkswagen rabbit custom diesel',\n",
              "       'ford fiesta', 'mazda glc deluxe', 'datsun b210 gx',\n",
              "       'oldsmobile cutlass salon brougham', 'dodge diplomat',\n",
              "       'mercury monarch ghia', 'pontiac phoenix lj',\n",
              "       'ford fairmont (auto)', 'ford fairmont (man)', 'plymouth volare',\n",
              "       'amc concord', 'buick century special', 'mercury zephyr',\n",
              "       'dodge aspen', 'amc concord d/l',\n",
              "       'buick regal sport coupe (turbo)', 'ford futura',\n",
              "       'dodge magnum xe', 'datsun 510', 'dodge omni',\n",
              "       'toyota celica gt liftback', 'plymouth sapporo',\n",
              "       'oldsmobile starfire sx', 'datsun 200-sx', 'audi 5000',\n",
              "       'volvo 264gl', 'saab 99gle', 'peugeot 604sl',\n",
              "       'volkswagen scirocco', 'honda accord lx', 'pontiac lemans v6',\n",
              "       'mercury zephyr 6', 'ford fairmont 4', 'amc concord dl 6',\n",
              "       'dodge aspen 6', 'ford ltd landau', 'mercury grand marquis',\n",
              "       'dodge st. regis', 'chevrolet malibu classic (sw)',\n",
              "       'chrysler lebaron town @ country (sw)', 'vw rabbit custom',\n",
              "       'maxda glc deluxe', 'dodge colt hatchback custom', 'amc spirit dl',\n",
              "       'mercedes benz 300d', 'cadillac eldorado', 'plymouth horizon',\n",
              "       'plymouth horizon tc3', 'datsun 210', 'fiat strada custom',\n",
              "       'buick skylark limited', 'chevrolet citation',\n",
              "       'oldsmobile omega brougham', 'pontiac phoenix',\n",
              "       'toyota corolla tercel', 'datsun 310', 'ford fairmont',\n",
              "       'audi 4000', 'toyota corona liftback', 'mazda 626',\n",
              "       'datsun 510 hatchback', 'mazda glc', 'vw rabbit c (diesel)',\n",
              "       'vw dasher (diesel)', 'audi 5000s (diesel)', 'mercedes-benz 240d',\n",
              "       'honda civic 1500 gl', 'renault lecar deluxe', 'vokswagen rabbit',\n",
              "       'datsun 280-zx', 'mazda rx-7 gs', 'triumph tr7 coupe',\n",
              "       'ford mustang cobra', 'honda accord', 'plymouth reliant',\n",
              "       'dodge aries wagon (sw)', 'toyota starlet', 'plymouth champ',\n",
              "       'honda civic 1300', 'datsun 210 mpg', 'toyota tercel',\n",
              "       'mazda glc 4', 'plymouth horizon 4', 'ford escort 4w',\n",
              "       'ford escort 2h', 'volkswagen jetta', 'renault 18i',\n",
              "       'honda prelude', 'datsun 200sx', 'peugeot 505s turbo diesel',\n",
              "       'volvo diesel', 'toyota cressida', 'datsun 810 maxima',\n",
              "       'oldsmobile cutlass ls', 'ford granada gl',\n",
              "       'chrysler lebaron salon', 'chevrolet cavalier',\n",
              "       'chevrolet cavalier wagon', 'chevrolet cavalier 2-door',\n",
              "       'pontiac j2000 se hatchback', 'dodge aries se',\n",
              "       'ford fairmont futura', 'amc concord dl', 'volkswagen rabbit l',\n",
              "       'mazda glc custom l', 'mazda glc custom', 'plymouth horizon miser',\n",
              "       'mercury lynx l', 'nissan stanza xe', 'honda civic (auto)',\n",
              "       'datsun 310 gx', 'buick century limited',\n",
              "       'oldsmobile cutlass ciera (diesel)', 'chrysler lebaron medallion',\n",
              "       'ford granada l', 'toyota celica gt', 'dodge charger 2.2',\n",
              "       'chevrolet camaro', 'ford mustang gl', 'vw pickup',\n",
              "       'dodge rampage', 'ford ranger', 'chevy s-10'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC7mpauTYtLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8a8f6982-fce0-460b-d648-9221784d7749"
      },
      "source": [
        "for i in range(len(dataset['horsepower'])):\n",
        "  if dataset['horsepower'][i]  == '?':\n",
        "    print(\"None\",i)\n",
        "    dataset['horsepower'][i] = np.nan\n",
        "  \n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None 32\n",
            "None 126\n",
            "None 330\n",
            "None 336\n",
            "None 354\n",
            "None 374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuaU8WwglXMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9a0901b5-fc99-4815-f035-64b77c1e885c"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      6\n",
              "weight          0\n",
              "acceleration    0\n",
              "model year      0\n",
              "origin          0\n",
              "car name        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_LN8PnlY6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.dropna(inplace = True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5sBw9LNlguJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f6c9972b-fc8b-4f70-ee4d-2f1a0cf84035"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 392 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           392 non-null    float64\n",
            " 1   cylinders     392 non-null    int64  \n",
            " 2   displacement  392 non-null    float64\n",
            " 3   horsepower    392 non-null    object \n",
            " 4   weight        392 non-null    int64  \n",
            " 5   acceleration  392 non-null    float64\n",
            " 6   model year    392 non-null    int64  \n",
            " 7   origin        392 non-null    int64  \n",
            " 8   car name      392 non-null    object \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 30.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOfXt8ByljbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = dataset['horsepower']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7ToyIBllB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = np.array(horse)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMn_jjawlmXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(horse)):\n",
        "  horse[i] = int(horse[i])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWi1F2j1ln0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = horse.astype('int')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blk1yPbelpts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = pd.DataFrame(horse)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gXQAU4ilrSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94903454-f6a0-4cf2-b67a-7311a2dd8a93"
      },
      "source": [
        "type(horse)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEyJ_IDDltQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "caf0d9d4-991c-4569-9975-d04c448d75f7"
      },
      "source": [
        "print(horse)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0\n",
            "0    130\n",
            "1    165\n",
            "2    150\n",
            "3    150\n",
            "4    140\n",
            "..   ...\n",
            "387   86\n",
            "388   52\n",
            "389   84\n",
            "390   79\n",
            "391   82\n",
            "\n",
            "[392 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jddmg0dulvoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop('horsepower', axis = 1, inplace = True)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9NJF6trlxOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.concat([dataset, horse], axis = 1)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CdL8C1ely0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa1f7af9-c428-4775-a2b3-0f91774d7cc3"
      },
      "source": [
        "len(dataset)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J96IRZWyl0kX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "046c50f1-ce93-4cfe-c400-638f21e7ea79"
      },
      "source": [
        "len(horse)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rPG6f_ql1r9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e28003db-43a0-453f-efdf-ae9a64fa601f"
      },
      "source": [
        "dataset.isna().sum()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             6\n",
              "cylinders       6\n",
              "displacement    6\n",
              "weight          6\n",
              "acceleration    6\n",
              "model year      6\n",
              "origin          6\n",
              "car name        6\n",
              "0               6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54GGhpXbl2zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.dropna(inplace = True)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3amBIal5dE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6f5a61f1-76ce-4a5b-d1da-73dcbba3a9a2"
      },
      "source": [
        "dataset.head()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car name</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>buick skylark 320</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>plymouth satellite</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>amc rebel sst</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ford torino</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ...  origin                   car name      0\n",
              "0  18.0        8.0         307.0  ...     1.0  chevrolet chevelle malibu  130.0\n",
              "1  15.0        8.0         350.0  ...     1.0          buick skylark 320  165.0\n",
              "2  18.0        8.0         318.0  ...     1.0         plymouth satellite  150.0\n",
              "3  16.0        8.0         304.0  ...     1.0              amc rebel sst  150.0\n",
              "4  17.0        8.0         302.0  ...     1.0                ford torino  140.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJqK21x9l7sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.rename(columns = {0:\"horsepower\"}, inplace = True)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS3LtXyYl9A1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b2a1b1d0-d70b-452c-97bf-51c42e12b270"
      },
      "source": [
        "dataset.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 386 entries, 0 to 391\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           386 non-null    float64\n",
            " 1   cylinders     386 non-null    float64\n",
            " 2   displacement  386 non-null    float64\n",
            " 3   weight        386 non-null    float64\n",
            " 4   acceleration  386 non-null    float64\n",
            " 5   model year    386 non-null    float64\n",
            " 6   origin        386 non-null    float64\n",
            " 7   car name      386 non-null    object \n",
            " 8   horsepower    386 non-null    float64\n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 30.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzrqUbStl-aT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f40fc825-0592-4c6e-b5a8-7864373bccc7"
      },
      "source": [
        "dataset.info()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 386 entries, 0 to 391\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           386 non-null    float64\n",
            " 1   cylinders     386 non-null    float64\n",
            " 2   displacement  386 non-null    float64\n",
            " 3   weight        386 non-null    float64\n",
            " 4   acceleration  386 non-null    float64\n",
            " 5   model year    386 non-null    float64\n",
            " 6   origin        386 non-null    float64\n",
            " 7   car name      386 non-null    object \n",
            " 8   horsepower    386 non-null    float64\n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 30.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jED_3D8kmQ1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop('car name', inplace = True, axis = 1)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYZ7WJYMUGDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "655ad9ff-ea90-41a9-c04a-a2e6303d9a18"
      },
      "source": [
        "dataset.describe()\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>horsepower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.320725</td>\n",
              "      <td>5.494819</td>\n",
              "      <td>195.459845</td>\n",
              "      <td>2983.686528</td>\n",
              "      <td>15.505440</td>\n",
              "      <td>75.886010</td>\n",
              "      <td>1.582902</td>\n",
              "      <td>104.559585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.765096</td>\n",
              "      <td>1.709021</td>\n",
              "      <td>105.092187</td>\n",
              "      <td>853.830503</td>\n",
              "      <td>2.721057</td>\n",
              "      <td>3.634247</td>\n",
              "      <td>0.808794</td>\n",
              "      <td>38.728731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>1613.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>46.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>2223.750000</td>\n",
              "      <td>13.725000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>75.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.150000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>2822.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>93.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>302.000000</td>\n",
              "      <td>3627.500000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>128.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>46.600000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>5140.000000</td>\n",
              "      <td>24.800000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>230.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              mpg   cylinders  displacement  ...  model year      origin  horsepower\n",
              "count  386.000000  386.000000    386.000000  ...  386.000000  386.000000  386.000000\n",
              "mean    23.320725    5.494819    195.459845  ...   75.886010    1.582902  104.559585\n",
              "std      7.765096    1.709021    105.092187  ...    3.634247    0.808794   38.728731\n",
              "min      9.000000    3.000000     68.000000  ...   70.000000    1.000000   46.000000\n",
              "25%     17.000000    4.000000    105.000000  ...   73.000000    1.000000   75.000000\n",
              "50%     22.150000    4.000000    151.000000  ...   76.000000    1.000000   93.500000\n",
              "75%     29.000000    8.000000    302.000000  ...   79.000000    2.000000  128.000000\n",
              "max     46.600000    8.000000    455.000000  ...   82.000000    3.000000  230.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DnWZI6PUHbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dataset.drop('mpg', axis = 1)\n",
        "y = dataset['mpg']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL--_pB5UJ2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "069183c0-235b-4376-98ab-ff100e26c94b"
      },
      "source": [
        "x\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>horsepower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>6.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>3015.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>4.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>2585.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>6.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>4.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>82.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>4.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>386 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cylinders  displacement  weight  ...  model year  origin  horsepower\n",
              "0          8.0         307.0  3504.0  ...        70.0     1.0       130.0\n",
              "1          8.0         350.0  3693.0  ...        70.0     1.0       165.0\n",
              "2          8.0         318.0  3436.0  ...        70.0     1.0       150.0\n",
              "3          8.0         304.0  3433.0  ...        70.0     1.0       150.0\n",
              "4          8.0         302.0  3449.0  ...        70.0     1.0       140.0\n",
              "..         ...           ...     ...  ...         ...     ...         ...\n",
              "387        6.0         262.0  3015.0  ...        82.0     1.0        86.0\n",
              "388        4.0         156.0  2585.0  ...        82.0     1.0        52.0\n",
              "389        6.0         232.0  2835.0  ...        82.0     1.0        84.0\n",
              "390        4.0         144.0  2665.0  ...        82.0     3.0        79.0\n",
              "391        4.0         135.0  2370.0  ...        82.0     1.0        82.0\n",
              "\n",
              "[386 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6D-pXDeUK_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 388, test_size = 0.2)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHwd3TGwUOkJ",
        "colab_type": "text"
      },
      "source": [
        "Normalizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnlpWMdaUMsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wz5vKNdUUO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxiakSpeUXPL",
        "colab_type": "text"
      },
      "source": [
        "Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXAlB5S7UVX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_dim = 7 ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5oHMk9dUZOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OySltTCJUaeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6f7755b2-7e6e-4ec7-d253-a556010b8ae0"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,737\n",
            "Trainable params: 4,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-QVfsMUcFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71d96ffb-7ba3-412b-e0c1-a57556da9c06"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(x_train, y_train,epochs=EPOCHS, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 582.1754 - mae: 22.7010 - mse: 582.1754 - val_loss: 549.6410 - val_mae: 21.9650 - val_mse: 549.6410\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 539.5975 - mae: 21.6512 - mse: 539.5975 - val_loss: 506.9999 - val_mae: 20.8563 - val_mse: 506.9999\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 495.5464 - mae: 20.5017 - mse: 495.5464 - val_loss: 461.2857 - val_mae: 19.5971 - val_mse: 461.2857\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 447.6174 - mae: 19.1871 - mse: 447.6174 - val_loss: 411.8921 - val_mae: 18.2206 - val_mse: 411.8921\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 397.5275 - mae: 17.8036 - mse: 397.5275 - val_loss: 361.0833 - val_mae: 16.8780 - val_mse: 361.0833\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 345.0189 - mae: 16.4271 - mse: 345.0189 - val_loss: 308.3750 - val_mae: 15.4740 - val_mse: 308.3750\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 292.2794 - mae: 14.9673 - mse: 292.2794 - val_loss: 256.1943 - val_mae: 14.0559 - val_mse: 256.1943\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 239.2024 - mae: 13.5298 - mse: 239.2024 - val_loss: 202.4681 - val_mae: 12.5028 - val_mse: 202.4681\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 186.3445 - mae: 11.9484 - mse: 186.3445 - val_loss: 152.5120 - val_mae: 10.8125 - val_mse: 152.5120\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 138.5446 - mae: 10.2671 - mse: 138.5446 - val_loss: 107.7622 - val_mae: 8.9952 - val_mse: 107.7622\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 96.8419 - mae: 8.5374 - mse: 96.8419 - val_loss: 71.4851 - val_mae: 7.2839 - val_mse: 71.4851\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 64.3095 - mae: 6.8695 - mse: 64.3095 - val_loss: 45.5770 - val_mae: 5.8028 - val_mse: 45.5770\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 42.6187 - mae: 5.4543 - mse: 42.6187 - val_loss: 30.8340 - val_mae: 4.6819 - val_mse: 30.8340\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 31.1049 - mae: 4.5789 - mse: 31.1049 - val_loss: 24.3893 - val_mae: 4.0440 - val_mse: 24.3893\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.3329 - mae: 4.0996 - mse: 25.3329 - val_loss: 21.2594 - val_mae: 3.6518 - val_mse: 21.2594\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 22.3316 - mae: 3.8461 - mse: 22.3316 - val_loss: 19.2453 - val_mae: 3.4094 - val_mse: 19.2453\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 19.8815 - mae: 3.5943 - mse: 19.8815 - val_loss: 17.7937 - val_mae: 3.2341 - val_mse: 17.7937\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.5255 - mae: 3.4456 - mse: 18.5255 - val_loss: 16.4994 - val_mae: 3.0827 - val_mse: 16.4994\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 16.7222 - mae: 3.2318 - mse: 16.7222 - val_loss: 15.7026 - val_mae: 2.9641 - val_mse: 15.7026\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15.6675 - mae: 3.1221 - mse: 15.6675 - val_loss: 14.8089 - val_mae: 2.8708 - val_mse: 14.8089\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 14.6645 - mae: 2.9871 - mse: 14.6645 - val_loss: 14.1480 - val_mae: 2.7547 - val_mse: 14.1480\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 13.8714 - mae: 2.8626 - mse: 13.8714 - val_loss: 13.5071 - val_mae: 2.7082 - val_mse: 13.5071\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.3087 - mae: 2.8124 - mse: 13.3087 - val_loss: 13.1482 - val_mae: 2.6269 - val_mse: 13.1482\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.8639 - mae: 2.7253 - mse: 12.8639 - val_loss: 12.5930 - val_mae: 2.5584 - val_mse: 12.5930\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.2408 - mae: 2.6430 - mse: 12.2408 - val_loss: 12.5757 - val_mae: 2.6001 - val_mse: 12.5757\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.8189 - mae: 2.6068 - mse: 11.8189 - val_loss: 12.1527 - val_mae: 2.4983 - val_mse: 12.1527\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 11.7686 - mae: 2.5908 - mse: 11.7686 - val_loss: 11.6793 - val_mae: 2.4186 - val_mse: 11.6793\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.2144 - mae: 2.5136 - mse: 11.2144 - val_loss: 11.7080 - val_mae: 2.4456 - val_mse: 11.7080\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.8426 - mae: 2.4489 - mse: 10.8426 - val_loss: 11.3969 - val_mae: 2.4082 - val_mse: 11.3969\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.7184 - mae: 2.4089 - mse: 10.7184 - val_loss: 11.0779 - val_mae: 2.3524 - val_mse: 11.0779\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.6595 - mae: 2.4230 - mse: 10.6595 - val_loss: 11.0253 - val_mae: 2.3457 - val_mse: 11.0253\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.0466 - mae: 2.3717 - mse: 10.0466 - val_loss: 10.7049 - val_mae: 2.2688 - val_mse: 10.7049\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.2153 - mae: 2.3469 - mse: 10.2153 - val_loss: 10.9587 - val_mae: 2.3548 - val_mse: 10.9587\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7743 - mae: 2.3058 - mse: 9.7743 - val_loss: 10.6182 - val_mae: 2.2814 - val_mse: 10.6182\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7334 - mae: 2.2859 - mse: 9.7334 - val_loss: 10.3294 - val_mae: 2.2245 - val_mse: 10.3294\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.3268 - mae: 2.2717 - mse: 9.3268 - val_loss: 10.5189 - val_mae: 2.2890 - val_mse: 10.5189\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0606 - mae: 2.2386 - mse: 9.0606 - val_loss: 10.4848 - val_mae: 2.2443 - val_mse: 10.4848\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.2598 - mae: 2.2575 - mse: 9.2598 - val_loss: 9.9692 - val_mae: 2.2104 - val_mse: 9.9692\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8969 - mae: 2.1986 - mse: 8.8969 - val_loss: 9.8173 - val_mae: 2.1332 - val_mse: 9.8173\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.0354 - mae: 2.2173 - mse: 9.0354 - val_loss: 9.7210 - val_mae: 2.1209 - val_mse: 9.7210\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.7596 - mae: 2.1669 - mse: 8.7596 - val_loss: 9.6416 - val_mae: 2.1174 - val_mse: 9.6416\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4047 - mae: 2.1508 - mse: 8.4047 - val_loss: 9.8989 - val_mae: 2.1609 - val_mse: 9.8989\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2729 - mae: 2.1041 - mse: 8.2729 - val_loss: 10.2641 - val_mae: 2.2365 - val_mse: 10.2641\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.6185 - mae: 2.1519 - mse: 8.6185 - val_loss: 9.4188 - val_mae: 2.0694 - val_mse: 9.4188\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2651 - mae: 2.0933 - mse: 8.2651 - val_loss: 9.3366 - val_mae: 2.0703 - val_mse: 9.3366\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.3589 - mae: 2.0938 - mse: 8.3589 - val_loss: 9.3852 - val_mae: 2.0436 - val_mse: 9.3852\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1935 - mae: 2.0990 - mse: 8.1935 - val_loss: 9.3246 - val_mae: 2.0753 - val_mse: 9.3246\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8300 - mae: 2.0543 - mse: 7.8300 - val_loss: 9.3782 - val_mae: 2.0666 - val_mse: 9.3782\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.0253 - mae: 2.0864 - mse: 8.0253 - val_loss: 9.1589 - val_mae: 2.0602 - val_mse: 9.1589\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6809 - mae: 2.0270 - mse: 7.6809 - val_loss: 9.2067 - val_mae: 2.0307 - val_mse: 9.2067\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8552 - mae: 2.0574 - mse: 7.8552 - val_loss: 9.2715 - val_mae: 2.0760 - val_mse: 9.2715\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6778 - mae: 2.0333 - mse: 7.6778 - val_loss: 9.0870 - val_mae: 2.0084 - val_mse: 9.0870\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7074 - mae: 2.0401 - mse: 7.7074 - val_loss: 8.9553 - val_mae: 2.0014 - val_mse: 8.9553\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6320 - mae: 2.0286 - mse: 7.6320 - val_loss: 8.9427 - val_mae: 2.0325 - val_mse: 8.9427\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.3940 - mae: 2.0126 - mse: 7.3940 - val_loss: 8.9669 - val_mae: 2.0157 - val_mse: 8.9669\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.3141 - mae: 1.9890 - mse: 7.3141 - val_loss: 9.1481 - val_mae: 2.0221 - val_mse: 9.1481\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1595 - mae: 1.9558 - mse: 7.1595 - val_loss: 9.2064 - val_mae: 2.0894 - val_mse: 9.2064\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2052 - mae: 1.9689 - mse: 7.2052 - val_loss: 8.9957 - val_mae: 1.9876 - val_mse: 8.9957\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.1045 - mae: 1.9503 - mse: 7.1045 - val_loss: 9.0764 - val_mae: 2.1062 - val_mse: 9.0764\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4046 - mae: 2.0076 - mse: 7.4046 - val_loss: 9.1061 - val_mae: 2.0543 - val_mse: 9.1061\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.0383 - mae: 1.9325 - mse: 7.0383 - val_loss: 8.8837 - val_mae: 1.9872 - val_mse: 8.8837\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8789 - mae: 1.9224 - mse: 6.8789 - val_loss: 8.9920 - val_mae: 2.0749 - val_mse: 8.9920\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9991 - mae: 1.9382 - mse: 6.9991 - val_loss: 9.2321 - val_mae: 2.0872 - val_mse: 9.2321\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.0021 - mae: 1.9542 - mse: 7.0021 - val_loss: 8.6768 - val_mae: 1.9911 - val_mse: 8.6768\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8691 - mae: 1.9191 - mse: 6.8691 - val_loss: 8.9445 - val_mae: 2.0120 - val_mse: 8.9445\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9682 - mae: 1.9608 - mse: 6.9682 - val_loss: 8.9978 - val_mae: 2.1036 - val_mse: 8.9978\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8556 - mae: 1.9049 - mse: 6.8556 - val_loss: 8.7435 - val_mae: 2.0175 - val_mse: 8.7435\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8624 - mae: 1.8910 - mse: 6.8624 - val_loss: 8.9792 - val_mae: 2.0009 - val_mse: 8.9792\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9350 - mae: 1.9351 - mse: 6.9350 - val_loss: 9.0000 - val_mae: 2.0307 - val_mse: 9.0000\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8033 - mae: 1.9012 - mse: 6.8033 - val_loss: 8.6991 - val_mae: 1.9883 - val_mse: 8.6991\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6660 - mae: 1.8969 - mse: 6.6660 - val_loss: 8.6018 - val_mae: 1.9858 - val_mse: 8.6018\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5334 - mae: 1.8896 - mse: 6.5334 - val_loss: 8.6194 - val_mae: 1.9632 - val_mse: 8.6194\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.6039 - mae: 1.8607 - mse: 6.6039 - val_loss: 8.5605 - val_mae: 1.9527 - val_mse: 8.5605\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.5082 - mae: 1.8756 - mse: 6.5082 - val_loss: 8.7892 - val_mae: 2.0596 - val_mse: 8.7892\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5609 - mae: 1.8586 - mse: 6.5609 - val_loss: 8.9156 - val_mae: 2.0929 - val_mse: 8.9156\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3582 - mae: 1.8301 - mse: 6.3582 - val_loss: 8.5708 - val_mae: 1.9723 - val_mse: 8.5708\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4775 - mae: 1.8733 - mse: 6.4775 - val_loss: 8.8122 - val_mae: 2.0031 - val_mse: 8.8122\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3098 - mae: 1.8558 - mse: 6.3098 - val_loss: 8.4875 - val_mae: 1.9684 - val_mse: 8.4875\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3675 - mae: 1.8443 - mse: 6.3675 - val_loss: 8.7441 - val_mae: 2.0101 - val_mse: 8.7441\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3171 - mae: 1.8377 - mse: 6.3171 - val_loss: 8.6827 - val_mae: 1.9867 - val_mse: 8.6827\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2974 - mae: 1.8437 - mse: 6.2974 - val_loss: 8.7001 - val_mae: 1.9675 - val_mse: 8.7001\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4731 - mae: 1.8475 - mse: 6.4731 - val_loss: 8.5225 - val_mae: 1.9520 - val_mse: 8.5225\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2124 - mae: 1.8335 - mse: 6.2124 - val_loss: 8.6704 - val_mae: 2.0307 - val_mse: 8.6704\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2719 - mae: 1.8595 - mse: 6.2719 - val_loss: 8.5792 - val_mae: 1.9859 - val_mse: 8.5792\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.2175 - mae: 1.8197 - mse: 6.2175 - val_loss: 8.6241 - val_mae: 2.0038 - val_mse: 8.6241\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1667 - mae: 1.8472 - mse: 6.1667 - val_loss: 8.7506 - val_mae: 1.9846 - val_mse: 8.7506\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3119 - mae: 1.8406 - mse: 6.3119 - val_loss: 8.6029 - val_mae: 2.0061 - val_mse: 8.6029\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0715 - mae: 1.7991 - mse: 6.0715 - val_loss: 8.5460 - val_mae: 2.0048 - val_mse: 8.5460\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0791 - mae: 1.8346 - mse: 6.0791 - val_loss: 8.6785 - val_mae: 1.9692 - val_mse: 8.6785\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1492 - mae: 1.8201 - mse: 6.1492 - val_loss: 8.6345 - val_mae: 2.0010 - val_mse: 8.6345\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0830 - mae: 1.8004 - mse: 6.0830 - val_loss: 8.5390 - val_mae: 1.9981 - val_mse: 8.5390\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9734 - mae: 1.8005 - mse: 5.9734 - val_loss: 9.2452 - val_mae: 2.0810 - val_mse: 9.2452\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2826 - mae: 1.8415 - mse: 6.2826 - val_loss: 8.3981 - val_mae: 1.9435 - val_mse: 8.3981\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.1057 - mae: 1.8287 - mse: 6.1057 - val_loss: 8.3650 - val_mae: 1.9438 - val_mse: 8.3650\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7964 - mae: 1.7906 - mse: 5.7964 - val_loss: 8.9100 - val_mae: 2.0670 - val_mse: 8.9100\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.0467 - mae: 1.8011 - mse: 6.0467 - val_loss: 8.4026 - val_mae: 1.9555 - val_mse: 8.4026\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8625 - mae: 1.7964 - mse: 5.8625 - val_loss: 8.4808 - val_mae: 1.9409 - val_mse: 8.4808\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9903 - mae: 1.7917 - mse: 5.9903 - val_loss: 8.3702 - val_mae: 1.9255 - val_mse: 8.3702\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9229 - mae: 1.8094 - mse: 5.9229 - val_loss: 9.0696 - val_mae: 2.0678 - val_mse: 9.0696\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9230 - mae: 1.8021 - mse: 5.9230 - val_loss: 8.5167 - val_mae: 1.9658 - val_mse: 8.5167\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.9239 - mae: 1.7960 - mse: 5.9239 - val_loss: 8.5164 - val_mae: 1.9843 - val_mse: 8.5164\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7674 - mae: 1.7694 - mse: 5.7674 - val_loss: 8.5541 - val_mae: 1.9706 - val_mse: 8.5541\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7985 - mae: 1.7594 - mse: 5.7985 - val_loss: 8.7096 - val_mae: 1.9718 - val_mse: 8.7096\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8468 - mae: 1.7618 - mse: 5.8468 - val_loss: 8.6776 - val_mae: 2.0149 - val_mse: 8.6776\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8106 - mae: 1.7547 - mse: 5.8106 - val_loss: 8.5024 - val_mae: 1.9691 - val_mse: 8.5024\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7878 - mae: 1.7778 - mse: 5.7878 - val_loss: 8.6189 - val_mae: 1.9838 - val_mse: 8.6189\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6525 - mae: 1.7413 - mse: 5.6525 - val_loss: 8.4999 - val_mae: 1.9403 - val_mse: 8.4999\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8617 - mae: 1.7681 - mse: 5.8617 - val_loss: 8.4562 - val_mae: 1.9865 - val_mse: 8.4562\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6244 - mae: 1.7562 - mse: 5.6244 - val_loss: 8.5966 - val_mae: 1.9522 - val_mse: 8.5966\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5631 - mae: 1.7603 - mse: 5.5631 - val_loss: 8.8132 - val_mae: 1.9962 - val_mse: 8.8132\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5480 - mae: 1.7361 - mse: 5.5480 - val_loss: 8.8210 - val_mae: 2.0121 - val_mse: 8.8210\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7246 - mae: 1.7417 - mse: 5.7246 - val_loss: 8.4801 - val_mae: 1.9656 - val_mse: 8.4801\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5881 - mae: 1.7416 - mse: 5.5881 - val_loss: 8.7774 - val_mae: 2.0922 - val_mse: 8.7774\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7299 - mae: 1.7806 - mse: 5.7299 - val_loss: 8.4664 - val_mae: 1.9426 - val_mse: 8.4664\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.6723 - mae: 1.7506 - mse: 5.6723 - val_loss: 9.0287 - val_mae: 2.0890 - val_mse: 9.0287\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.7684 - mae: 1.7603 - mse: 5.7684 - val_loss: 8.3837 - val_mae: 1.9729 - val_mse: 8.3837\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6539 - mae: 1.7436 - mse: 5.6539 - val_loss: 8.5938 - val_mae: 2.0181 - val_mse: 8.5938\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3152 - mae: 1.7433 - mse: 5.3152 - val_loss: 8.9756 - val_mae: 2.0996 - val_mse: 8.9756\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6692 - mae: 1.7275 - mse: 5.6692 - val_loss: 8.5342 - val_mae: 1.9935 - val_mse: 8.5342\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4673 - mae: 1.7232 - mse: 5.4673 - val_loss: 8.3764 - val_mae: 1.9511 - val_mse: 8.3764\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6392 - mae: 1.7292 - mse: 5.6392 - val_loss: 8.4555 - val_mae: 1.9625 - val_mse: 8.4555\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.3940 - mae: 1.7020 - mse: 5.3940 - val_loss: 8.5277 - val_mae: 1.9663 - val_mse: 8.5277\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4209 - mae: 1.7209 - mse: 5.4209 - val_loss: 8.4290 - val_mae: 1.9728 - val_mse: 8.4290\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3297 - mae: 1.7030 - mse: 5.3297 - val_loss: 8.5896 - val_mae: 2.0353 - val_mse: 8.5896\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3102 - mae: 1.7064 - mse: 5.3102 - val_loss: 8.9443 - val_mae: 2.0395 - val_mse: 8.9443\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4809 - mae: 1.7401 - mse: 5.4809 - val_loss: 8.3171 - val_mae: 1.9365 - val_mse: 8.3171\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3366 - mae: 1.6792 - mse: 5.3366 - val_loss: 8.5973 - val_mae: 1.9826 - val_mse: 8.5973\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4743 - mae: 1.7175 - mse: 5.4743 - val_loss: 8.3844 - val_mae: 1.9515 - val_mse: 8.3844\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2712 - mae: 1.6892 - mse: 5.2712 - val_loss: 9.0057 - val_mae: 2.0822 - val_mse: 9.0057\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4400 - mae: 1.7201 - mse: 5.4400 - val_loss: 8.2314 - val_mae: 1.9070 - val_mse: 8.2314\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4059 - mae: 1.7249 - mse: 5.4059 - val_loss: 8.3201 - val_mae: 1.9362 - val_mse: 8.3201\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5152 - mae: 1.7347 - mse: 5.5152 - val_loss: 8.3475 - val_mae: 1.9111 - val_mse: 8.3475\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.2813 - mae: 1.6839 - mse: 5.2813 - val_loss: 8.2726 - val_mae: 1.9271 - val_mse: 8.2726\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3141 - mae: 1.6935 - mse: 5.3141 - val_loss: 8.6162 - val_mae: 1.9869 - val_mse: 8.6162\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2398 - mae: 1.6901 - mse: 5.2398 - val_loss: 8.2366 - val_mae: 1.9022 - val_mse: 8.2366\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2015 - mae: 1.7115 - mse: 5.2015 - val_loss: 8.3871 - val_mae: 2.0011 - val_mse: 8.3871\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3083 - mae: 1.6721 - mse: 5.3083 - val_loss: 8.1859 - val_mae: 1.8839 - val_mse: 8.1859\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3090 - mae: 1.6849 - mse: 5.3090 - val_loss: 8.3842 - val_mae: 1.9394 - val_mse: 8.3842\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2441 - mae: 1.7060 - mse: 5.2441 - val_loss: 8.5846 - val_mae: 2.0251 - val_mse: 8.5846\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2509 - mae: 1.6702 - mse: 5.2509 - val_loss: 8.4693 - val_mae: 1.9816 - val_mse: 8.4693\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2059 - mae: 1.6761 - mse: 5.2059 - val_loss: 8.4455 - val_mae: 2.0003 - val_mse: 8.4455\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1228 - mae: 1.6571 - mse: 5.1228 - val_loss: 8.3183 - val_mae: 1.9403 - val_mse: 8.3183\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0639 - mae: 1.6669 - mse: 5.0639 - val_loss: 8.4557 - val_mae: 1.9375 - val_mse: 8.4557\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.1369 - mae: 1.6585 - mse: 5.1369 - val_loss: 8.2713 - val_mae: 1.9331 - val_mse: 8.2713\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0112 - mae: 1.6377 - mse: 5.0112 - val_loss: 8.5291 - val_mae: 1.9894 - val_mse: 8.5291\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4493 - mae: 1.6853 - mse: 5.4493 - val_loss: 8.2453 - val_mae: 1.8989 - val_mse: 8.2453\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1300 - mae: 1.6764 - mse: 5.1300 - val_loss: 8.2714 - val_mae: 1.9080 - val_mse: 8.2714\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0141 - mae: 1.6429 - mse: 5.0141 - val_loss: 8.3812 - val_mae: 1.9134 - val_mse: 8.3812\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9725 - mae: 1.6110 - mse: 4.9725 - val_loss: 8.1643 - val_mae: 1.9099 - val_mse: 8.1643\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9712 - mae: 1.6339 - mse: 4.9712 - val_loss: 8.1427 - val_mae: 1.9289 - val_mse: 8.1427\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2503 - mae: 1.6801 - mse: 5.2503 - val_loss: 8.0448 - val_mae: 1.8797 - val_mse: 8.0448\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9929 - mae: 1.6371 - mse: 4.9929 - val_loss: 8.1592 - val_mae: 1.9278 - val_mse: 8.1592\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.9019 - mae: 1.6337 - mse: 4.9019 - val_loss: 8.1187 - val_mae: 1.9047 - val_mse: 8.1187\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0939 - mae: 1.6345 - mse: 5.0939 - val_loss: 8.4853 - val_mae: 1.9757 - val_mse: 8.4853\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8719 - mae: 1.6356 - mse: 4.8719 - val_loss: 8.3111 - val_mae: 1.9467 - val_mse: 8.3111\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7203 - mae: 1.6095 - mse: 4.7203 - val_loss: 8.9655 - val_mae: 2.0086 - val_mse: 8.9655\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9438 - mae: 1.6109 - mse: 4.9438 - val_loss: 8.5283 - val_mae: 1.9377 - val_mse: 8.5283\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1550 - mae: 1.6331 - mse: 5.1550 - val_loss: 8.3021 - val_mae: 1.9499 - val_mse: 8.3021\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8899 - mae: 1.6006 - mse: 4.8899 - val_loss: 8.0824 - val_mae: 1.8960 - val_mse: 8.0824\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9854 - mae: 1.6320 - mse: 4.9854 - val_loss: 8.1030 - val_mae: 1.9084 - val_mse: 8.1030\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7596 - mae: 1.5894 - mse: 4.7596 - val_loss: 8.0044 - val_mae: 1.8686 - val_mse: 8.0044\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0156 - mae: 1.6517 - mse: 5.0156 - val_loss: 8.2168 - val_mae: 1.8935 - val_mse: 8.2168\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8991 - mae: 1.6075 - mse: 4.8991 - val_loss: 8.6305 - val_mae: 1.9881 - val_mse: 8.6305\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8482 - mae: 1.5990 - mse: 4.8482 - val_loss: 8.1827 - val_mae: 1.9251 - val_mse: 8.1827\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8063 - mae: 1.5979 - mse: 4.8063 - val_loss: 8.2823 - val_mae: 1.9433 - val_mse: 8.2823\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7114 - mae: 1.5900 - mse: 4.7114 - val_loss: 8.0629 - val_mae: 1.8898 - val_mse: 8.0629\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8461 - mae: 1.5959 - mse: 4.8461 - val_loss: 8.0300 - val_mae: 1.8897 - val_mse: 8.0300\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.8337 - mae: 1.5821 - mse: 4.8337 - val_loss: 8.0953 - val_mae: 1.9201 - val_mse: 8.0953\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6499 - mae: 1.5924 - mse: 4.6499 - val_loss: 8.5360 - val_mae: 1.9579 - val_mse: 8.5360\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7948 - mae: 1.6269 - mse: 4.7948 - val_loss: 8.3627 - val_mae: 1.9338 - val_mse: 8.3627\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7931 - mae: 1.6134 - mse: 4.7931 - val_loss: 8.0589 - val_mae: 1.8778 - val_mse: 8.0589\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6696 - mae: 1.5668 - mse: 4.6696 - val_loss: 8.1119 - val_mae: 1.9107 - val_mse: 8.1119\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8027 - mae: 1.6093 - mse: 4.8027 - val_loss: 8.0387 - val_mae: 1.8841 - val_mse: 8.0387\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8801 - mae: 1.5797 - mse: 4.8801 - val_loss: 8.0535 - val_mae: 1.8931 - val_mse: 8.0535\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8316 - mae: 1.5868 - mse: 4.8316 - val_loss: 8.0098 - val_mae: 1.9059 - val_mse: 8.0098\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6640 - mae: 1.5690 - mse: 4.6640 - val_loss: 8.0034 - val_mae: 1.8858 - val_mse: 8.0034\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7586 - mae: 1.5754 - mse: 4.7586 - val_loss: 8.1089 - val_mae: 1.8770 - val_mse: 8.1089\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5315 - mae: 1.5539 - mse: 4.5315 - val_loss: 8.4163 - val_mae: 1.9317 - val_mse: 8.4163\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7558 - mae: 1.5748 - mse: 4.7558 - val_loss: 8.2507 - val_mae: 1.9630 - val_mse: 8.2507\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5909 - mae: 1.5431 - mse: 4.5909 - val_loss: 8.0724 - val_mae: 1.8627 - val_mse: 8.0724\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6156 - mae: 1.5434 - mse: 4.6156 - val_loss: 8.3873 - val_mae: 1.9421 - val_mse: 8.3873\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8423 - mae: 1.6119 - mse: 4.8423 - val_loss: 8.1067 - val_mae: 1.8951 - val_mse: 8.1067\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6350 - mae: 1.5511 - mse: 4.6350 - val_loss: 8.4648 - val_mae: 1.9669 - val_mse: 8.4648\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5952 - mae: 1.5718 - mse: 4.5952 - val_loss: 8.2051 - val_mae: 1.9398 - val_mse: 8.2051\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6926 - mae: 1.5853 - mse: 4.6926 - val_loss: 8.1227 - val_mae: 1.9109 - val_mse: 8.1227\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5534 - mae: 1.5724 - mse: 4.5534 - val_loss: 8.3321 - val_mae: 1.9346 - val_mse: 8.3321\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5818 - mae: 1.5578 - mse: 4.5818 - val_loss: 8.5393 - val_mae: 1.9850 - val_mse: 8.5393\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5254 - mae: 1.5329 - mse: 4.5254 - val_loss: 8.1436 - val_mae: 1.8972 - val_mse: 8.1436\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.5676 - mae: 1.5598 - mse: 4.5676 - val_loss: 7.9757 - val_mae: 1.8967 - val_mse: 7.9757\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4827 - mae: 1.5447 - mse: 4.4827 - val_loss: 8.1371 - val_mae: 1.9098 - val_mse: 8.1371\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5577 - mae: 1.5319 - mse: 4.5577 - val_loss: 8.3606 - val_mae: 2.0237 - val_mse: 8.3606\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7304 - mae: 1.5896 - mse: 4.7304 - val_loss: 8.0389 - val_mae: 1.8999 - val_mse: 8.0389\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7091 - mae: 1.5567 - mse: 4.7091 - val_loss: 8.3391 - val_mae: 1.9281 - val_mse: 8.3391\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5974 - mae: 1.5442 - mse: 4.5974 - val_loss: 8.1389 - val_mae: 1.8814 - val_mse: 8.1389\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3755 - mae: 1.5204 - mse: 4.3755 - val_loss: 8.2948 - val_mae: 1.9200 - val_mse: 8.2948\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6045 - mae: 1.5493 - mse: 4.6045 - val_loss: 8.0122 - val_mae: 1.8625 - val_mse: 8.0122\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4319 - mae: 1.5243 - mse: 4.4319 - val_loss: 8.4054 - val_mae: 1.9546 - val_mse: 8.4054\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3700 - mae: 1.5104 - mse: 4.3700 - val_loss: 8.1230 - val_mae: 1.9333 - val_mse: 8.1230\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.6220 - mae: 1.5858 - mse: 4.6220 - val_loss: 8.0263 - val_mae: 1.8987 - val_mse: 8.0263\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4039 - mae: 1.5310 - mse: 4.4039 - val_loss: 8.1427 - val_mae: 1.9030 - val_mse: 8.1427\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4439 - mae: 1.5421 - mse: 4.4439 - val_loss: 8.0135 - val_mae: 1.8988 - val_mse: 8.0135\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3333 - mae: 1.4905 - mse: 4.3333 - val_loss: 8.1167 - val_mae: 1.9701 - val_mse: 8.1167\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3560 - mae: 1.5169 - mse: 4.3560 - val_loss: 8.2944 - val_mae: 1.9230 - val_mse: 8.2944\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3502 - mae: 1.5368 - mse: 4.3502 - val_loss: 8.1730 - val_mae: 1.9242 - val_mse: 8.1730\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5420 - mae: 1.5350 - mse: 4.5420 - val_loss: 8.3936 - val_mae: 1.9803 - val_mse: 8.3936\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3711 - mae: 1.5223 - mse: 4.3711 - val_loss: 8.2224 - val_mae: 1.9218 - val_mse: 8.2224\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2419 - mae: 1.5072 - mse: 4.2419 - val_loss: 8.0470 - val_mae: 1.8773 - val_mse: 8.0470\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3779 - mae: 1.5136 - mse: 4.3779 - val_loss: 8.0485 - val_mae: 1.8761 - val_mse: 8.0485\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5649 - mae: 1.5421 - mse: 4.5649 - val_loss: 8.0438 - val_mae: 1.8996 - val_mse: 8.0438\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2854 - mae: 1.5232 - mse: 4.2854 - val_loss: 8.3422 - val_mae: 1.9886 - val_mse: 8.3422\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2965 - mae: 1.4874 - mse: 4.2965 - val_loss: 9.4147 - val_mae: 2.0818 - val_mse: 9.4147\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5239 - mae: 1.5473 - mse: 4.5239 - val_loss: 8.1994 - val_mae: 1.9040 - val_mse: 8.1994\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4476 - mae: 1.5222 - mse: 4.4476 - val_loss: 7.9304 - val_mae: 1.8679 - val_mse: 7.9304\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2936 - mae: 1.5060 - mse: 4.2936 - val_loss: 7.9872 - val_mae: 1.9063 - val_mse: 7.9872\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3136 - mae: 1.5019 - mse: 4.3136 - val_loss: 8.1716 - val_mae: 1.9200 - val_mse: 8.1716\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2884 - mae: 1.4833 - mse: 4.2884 - val_loss: 8.1428 - val_mae: 1.9130 - val_mse: 8.1428\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4125 - mae: 1.5463 - mse: 4.4125 - val_loss: 8.0976 - val_mae: 1.9060 - val_mse: 8.0976\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4151 - mae: 1.5601 - mse: 4.4151 - val_loss: 7.8877 - val_mae: 1.8844 - val_mse: 7.8877\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3558 - mae: 1.5055 - mse: 4.3558 - val_loss: 7.9249 - val_mae: 1.8877 - val_mse: 7.9249\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3518 - mae: 1.5143 - mse: 4.3518 - val_loss: 8.3531 - val_mae: 2.0303 - val_mse: 8.3531\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3026 - mae: 1.5285 - mse: 4.3026 - val_loss: 8.4114 - val_mae: 1.9956 - val_mse: 8.4114\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3642 - mae: 1.4818 - mse: 4.3642 - val_loss: 8.0869 - val_mae: 1.8800 - val_mse: 8.0869\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1870 - mae: 1.4759 - mse: 4.1870 - val_loss: 8.2124 - val_mae: 1.9300 - val_mse: 8.2124\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3670 - mae: 1.5177 - mse: 4.3670 - val_loss: 8.1970 - val_mae: 1.9213 - val_mse: 8.1970\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4824 - mae: 1.5374 - mse: 4.4824 - val_loss: 8.0616 - val_mae: 1.9109 - val_mse: 8.0616\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2439 - mae: 1.5026 - mse: 4.2439 - val_loss: 7.9769 - val_mae: 1.9327 - val_mse: 7.9769\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3011 - mae: 1.5114 - mse: 4.3011 - val_loss: 7.8953 - val_mae: 1.8840 - val_mse: 7.8953\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.3382 - mae: 1.5290 - mse: 4.3382 - val_loss: 7.9404 - val_mae: 1.8911 - val_mse: 7.9404\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0923 - mae: 1.4589 - mse: 4.0923 - val_loss: 7.8549 - val_mae: 1.8599 - val_mse: 7.8549\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1055 - mae: 1.4726 - mse: 4.1055 - val_loss: 8.0689 - val_mae: 1.9115 - val_mse: 8.0689\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4123 - mae: 1.5209 - mse: 4.4123 - val_loss: 8.3370 - val_mae: 1.9288 - val_mse: 8.3370\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3177 - mae: 1.5192 - mse: 4.3177 - val_loss: 7.9799 - val_mae: 1.9006 - val_mse: 7.9799\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1520 - mae: 1.4871 - mse: 4.1520 - val_loss: 8.2143 - val_mae: 1.9107 - val_mse: 8.2143\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2027 - mae: 1.4886 - mse: 4.2027 - val_loss: 7.9917 - val_mae: 1.9258 - val_mse: 7.9917\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2111 - mae: 1.5037 - mse: 4.2111 - val_loss: 8.0232 - val_mae: 1.9009 - val_mse: 8.0232\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3206 - mae: 1.4885 - mse: 4.3206 - val_loss: 8.0866 - val_mae: 1.9033 - val_mse: 8.0866\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.2052 - mae: 1.4642 - mse: 4.2052 - val_loss: 8.0324 - val_mae: 1.8885 - val_mse: 8.0324\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1254 - mae: 1.4653 - mse: 4.1254 - val_loss: 8.1151 - val_mae: 1.9349 - val_mse: 8.1151\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2385 - mae: 1.4982 - mse: 4.2385 - val_loss: 8.6080 - val_mae: 1.9610 - val_mse: 8.6080\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0866 - mae: 1.4748 - mse: 4.0866 - val_loss: 8.8013 - val_mae: 2.0433 - val_mse: 8.8013\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1976 - mae: 1.4705 - mse: 4.1976 - val_loss: 8.0006 - val_mae: 1.8982 - val_mse: 8.0006\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1045 - mae: 1.4609 - mse: 4.1045 - val_loss: 8.0935 - val_mae: 1.8753 - val_mse: 8.0935\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1644 - mae: 1.4915 - mse: 4.1644 - val_loss: 7.8271 - val_mae: 1.8382 - val_mse: 7.8271\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0630 - mae: 1.4569 - mse: 4.0630 - val_loss: 8.3571 - val_mae: 1.9399 - val_mse: 8.3571\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0468 - mae: 1.4459 - mse: 4.0468 - val_loss: 8.1886 - val_mae: 1.9061 - val_mse: 8.1886\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2159 - mae: 1.4499 - mse: 4.2159 - val_loss: 8.0326 - val_mae: 1.8915 - val_mse: 8.0326\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9491 - mae: 1.4359 - mse: 3.9491 - val_loss: 8.9801 - val_mae: 2.0245 - val_mse: 8.9801\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2030 - mae: 1.4832 - mse: 4.2030 - val_loss: 8.3820 - val_mae: 1.9921 - val_mse: 8.3820\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1621 - mae: 1.4571 - mse: 4.1621 - val_loss: 8.1008 - val_mae: 1.9323 - val_mse: 8.1008\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2145 - mae: 1.4707 - mse: 4.2145 - val_loss: 8.0548 - val_mae: 1.9304 - val_mse: 8.0548\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1548 - mae: 1.4671 - mse: 4.1548 - val_loss: 8.0471 - val_mae: 1.8964 - val_mse: 8.0471\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1770 - mae: 1.4570 - mse: 4.1770 - val_loss: 7.8703 - val_mae: 1.8744 - val_mse: 7.8703\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0141 - mae: 1.4468 - mse: 4.0141 - val_loss: 8.0751 - val_mae: 1.9301 - val_mse: 8.0751\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2044 - mae: 1.4509 - mse: 4.2044 - val_loss: 8.3361 - val_mae: 1.9260 - val_mse: 8.3361\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2199 - mae: 1.4791 - mse: 4.2199 - val_loss: 7.8895 - val_mae: 1.8810 - val_mse: 7.8895\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0582 - mae: 1.4477 - mse: 4.0582 - val_loss: 8.4061 - val_mae: 1.9795 - val_mse: 8.4061\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0192 - mae: 1.4572 - mse: 4.0192 - val_loss: 8.1062 - val_mae: 1.8910 - val_mse: 8.1062\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0973 - mae: 1.4496 - mse: 4.0973 - val_loss: 7.7508 - val_mae: 1.8390 - val_mse: 7.7508\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0119 - mae: 1.4479 - mse: 4.0119 - val_loss: 8.1604 - val_mae: 1.9587 - val_mse: 8.1604\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8672 - mae: 1.3934 - mse: 3.8672 - val_loss: 9.1063 - val_mae: 2.0344 - val_mse: 9.1063\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1496 - mae: 1.4539 - mse: 4.1496 - val_loss: 7.9800 - val_mae: 1.8912 - val_mse: 7.9800\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1322 - mae: 1.4652 - mse: 4.1322 - val_loss: 7.9169 - val_mae: 1.8945 - val_mse: 7.9169\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9782 - mae: 1.4612 - mse: 3.9782 - val_loss: 7.9135 - val_mae: 1.8515 - val_mse: 7.9135\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9905 - mae: 1.4324 - mse: 3.9905 - val_loss: 8.1960 - val_mae: 1.9537 - val_mse: 8.1960\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0345 - mae: 1.4423 - mse: 4.0345 - val_loss: 7.9657 - val_mae: 1.8863 - val_mse: 7.9657\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9395 - mae: 1.4351 - mse: 3.9395 - val_loss: 8.3976 - val_mae: 1.9403 - val_mse: 8.3976\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9989 - mae: 1.4232 - mse: 3.9989 - val_loss: 7.8374 - val_mae: 1.8972 - val_mse: 7.8374\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0534 - mae: 1.4393 - mse: 4.0534 - val_loss: 8.1074 - val_mae: 1.8887 - val_mse: 8.1074\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0116 - mae: 1.4411 - mse: 4.0116 - val_loss: 7.9459 - val_mae: 1.8696 - val_mse: 7.9459\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9549 - mae: 1.4121 - mse: 3.9549 - val_loss: 8.0063 - val_mae: 1.9094 - val_mse: 8.0063\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9198 - mae: 1.4341 - mse: 3.9198 - val_loss: 7.7246 - val_mae: 1.8727 - val_mse: 7.7246\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8070 - mae: 1.3916 - mse: 3.8070 - val_loss: 7.7919 - val_mae: 1.8705 - val_mse: 7.7919\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9767 - mae: 1.4287 - mse: 3.9767 - val_loss: 8.4550 - val_mae: 2.0026 - val_mse: 8.4550\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0126 - mae: 1.4500 - mse: 4.0126 - val_loss: 7.8716 - val_mae: 1.8474 - val_mse: 7.8716\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8769 - mae: 1.4081 - mse: 3.8769 - val_loss: 8.9180 - val_mae: 2.0106 - val_mse: 8.9180\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0261 - mae: 1.4394 - mse: 4.0261 - val_loss: 7.9451 - val_mae: 1.8883 - val_mse: 7.9451\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9263 - mae: 1.3950 - mse: 3.9263 - val_loss: 7.9013 - val_mae: 1.8821 - val_mse: 7.9013\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8740 - mae: 1.4376 - mse: 3.8740 - val_loss: 7.9498 - val_mae: 1.8700 - val_mse: 7.9498\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0706 - mae: 1.4300 - mse: 4.0706 - val_loss: 8.1113 - val_mae: 1.8867 - val_mse: 8.1113\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9866 - mae: 1.4397 - mse: 3.9866 - val_loss: 8.0062 - val_mae: 1.9201 - val_mse: 8.0062\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7640 - mae: 1.3845 - mse: 3.7640 - val_loss: 7.7933 - val_mae: 1.8774 - val_mse: 7.7933\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9194 - mae: 1.4277 - mse: 3.9194 - val_loss: 8.0561 - val_mae: 1.9216 - val_mse: 8.0561\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9226 - mae: 1.3943 - mse: 3.9226 - val_loss: 8.1468 - val_mae: 1.9126 - val_mse: 8.1468\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9327 - mae: 1.4201 - mse: 3.9327 - val_loss: 7.9360 - val_mae: 1.8967 - val_mse: 7.9360\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9781 - mae: 1.4208 - mse: 3.9781 - val_loss: 7.8926 - val_mae: 1.8867 - val_mse: 7.8926\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8562 - mae: 1.4228 - mse: 3.8562 - val_loss: 7.9259 - val_mae: 1.8885 - val_mse: 7.9259\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9397 - mae: 1.3935 - mse: 3.9397 - val_loss: 7.9823 - val_mae: 1.9352 - val_mse: 7.9823\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8516 - mae: 1.3950 - mse: 3.8516 - val_loss: 7.7750 - val_mae: 1.8414 - val_mse: 7.7750\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7674 - mae: 1.3817 - mse: 3.7674 - val_loss: 7.9932 - val_mae: 1.9391 - val_mse: 7.9932\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9919 - mae: 1.4147 - mse: 3.9919 - val_loss: 7.8713 - val_mae: 1.9000 - val_mse: 7.8713\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8998 - mae: 1.3969 - mse: 3.8998 - val_loss: 7.8153 - val_mae: 1.8937 - val_mse: 7.8153\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8688 - mae: 1.4218 - mse: 3.8688 - val_loss: 8.2103 - val_mae: 1.9284 - val_mse: 8.2103\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6781 - mae: 1.3596 - mse: 3.6781 - val_loss: 8.5097 - val_mae: 1.9318 - val_mse: 8.5097\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8845 - mae: 1.4443 - mse: 3.8845 - val_loss: 8.3931 - val_mae: 1.9211 - val_mse: 8.3931\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.7544 - mae: 1.3806 - mse: 3.7544 - val_loss: 7.8051 - val_mae: 1.9107 - val_mse: 7.8051\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6595 - mae: 1.4072 - mse: 3.6595 - val_loss: 8.4514 - val_mae: 1.9377 - val_mse: 8.4514\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8150 - mae: 1.4039 - mse: 3.8150 - val_loss: 7.8203 - val_mae: 1.9084 - val_mse: 7.8203\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8368 - mae: 1.3791 - mse: 3.8368 - val_loss: 8.2769 - val_mae: 1.9374 - val_mse: 8.2769\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7734 - mae: 1.3966 - mse: 3.7734 - val_loss: 8.0949 - val_mae: 1.9968 - val_mse: 8.0949\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7391 - mae: 1.3773 - mse: 3.7391 - val_loss: 7.9700 - val_mae: 1.8735 - val_mse: 7.9700\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6725 - mae: 1.3776 - mse: 3.6725 - val_loss: 8.4213 - val_mae: 1.9816 - val_mse: 8.4213\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1629 - mae: 1.4489 - mse: 4.1629 - val_loss: 7.9167 - val_mae: 1.9088 - val_mse: 7.9167\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6942 - mae: 1.3616 - mse: 3.6942 - val_loss: 7.9488 - val_mae: 1.9124 - val_mse: 7.9488\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8376 - mae: 1.4023 - mse: 3.8376 - val_loss: 7.7768 - val_mae: 1.8980 - val_mse: 7.7768\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7712 - mae: 1.4041 - mse: 3.7712 - val_loss: 7.8738 - val_mae: 1.8974 - val_mse: 7.8738\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5841 - mae: 1.3536 - mse: 3.5841 - val_loss: 8.1290 - val_mae: 1.9043 - val_mse: 8.1290\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7077 - mae: 1.3724 - mse: 3.7077 - val_loss: 7.7742 - val_mae: 1.8493 - val_mse: 7.7742\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7699 - mae: 1.3588 - mse: 3.7699 - val_loss: 7.8199 - val_mae: 1.8771 - val_mse: 7.8199\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7924 - mae: 1.3874 - mse: 3.7924 - val_loss: 7.7455 - val_mae: 1.8616 - val_mse: 7.7455\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6772 - mae: 1.3771 - mse: 3.6772 - val_loss: 8.6270 - val_mae: 1.9590 - val_mse: 8.6270\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6450 - mae: 1.3755 - mse: 3.6450 - val_loss: 7.9180 - val_mae: 1.8771 - val_mse: 7.9180\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8870 - mae: 1.3690 - mse: 3.8870 - val_loss: 7.8977 - val_mae: 1.8769 - val_mse: 7.8977\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5615 - mae: 1.3564 - mse: 3.5615 - val_loss: 7.8543 - val_mae: 1.9024 - val_mse: 7.8543\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9170 - mae: 1.4135 - mse: 3.9170 - val_loss: 8.3267 - val_mae: 1.9735 - val_mse: 8.3267\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6948 - mae: 1.3944 - mse: 3.6948 - val_loss: 7.9066 - val_mae: 1.8906 - val_mse: 7.9066\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5619 - mae: 1.3255 - mse: 3.5619 - val_loss: 7.9706 - val_mae: 1.9192 - val_mse: 7.9706\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5874 - mae: 1.3604 - mse: 3.5874 - val_loss: 7.7034 - val_mae: 1.8603 - val_mse: 7.7034\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7441 - mae: 1.3641 - mse: 3.7441 - val_loss: 7.7268 - val_mae: 1.8825 - val_mse: 7.7268\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7568 - mae: 1.3902 - mse: 3.7568 - val_loss: 7.7787 - val_mae: 1.8828 - val_mse: 7.7787\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6495 - mae: 1.3729 - mse: 3.6495 - val_loss: 7.9306 - val_mae: 1.9088 - val_mse: 7.9306\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6307 - mae: 1.3352 - mse: 3.6307 - val_loss: 8.6363 - val_mae: 1.9604 - val_mse: 8.6363\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6720 - mae: 1.3326 - mse: 3.6720 - val_loss: 9.3025 - val_mae: 2.0677 - val_mse: 9.3025\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8338 - mae: 1.4039 - mse: 3.8338 - val_loss: 8.3376 - val_mae: 1.9302 - val_mse: 8.3376\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8342 - mae: 1.3640 - mse: 3.8342 - val_loss: 7.9414 - val_mae: 1.9196 - val_mse: 7.9414\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5837 - mae: 1.3152 - mse: 3.5837 - val_loss: 7.9010 - val_mae: 1.9026 - val_mse: 7.9010\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5550 - mae: 1.3259 - mse: 3.5550 - val_loss: 7.7872 - val_mae: 1.8875 - val_mse: 7.7872\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6098 - mae: 1.3508 - mse: 3.6098 - val_loss: 7.7170 - val_mae: 1.8895 - val_mse: 7.7170\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9842 - mae: 1.4322 - mse: 3.9842 - val_loss: 7.7578 - val_mae: 1.8829 - val_mse: 7.7578\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7144 - mae: 1.3225 - mse: 3.7144 - val_loss: 7.7411 - val_mae: 1.8625 - val_mse: 7.7411\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6019 - mae: 1.3388 - mse: 3.6019 - val_loss: 7.9576 - val_mae: 1.9437 - val_mse: 7.9576\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4672 - mae: 1.3156 - mse: 3.4672 - val_loss: 7.9206 - val_mae: 1.8863 - val_mse: 7.9206\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6933 - mae: 1.3693 - mse: 3.6933 - val_loss: 7.9519 - val_mae: 1.9098 - val_mse: 7.9519\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5688 - mae: 1.3406 - mse: 3.5688 - val_loss: 7.9582 - val_mae: 1.9185 - val_mse: 7.9582\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6252 - mae: 1.3603 - mse: 3.6252 - val_loss: 8.5132 - val_mae: 1.9463 - val_mse: 8.5132\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6695 - mae: 1.3655 - mse: 3.6695 - val_loss: 7.6387 - val_mae: 1.8686 - val_mse: 7.6387\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5207 - mae: 1.3295 - mse: 3.5207 - val_loss: 8.1800 - val_mae: 1.9116 - val_mse: 8.1800\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7708 - mae: 1.3551 - mse: 3.7708 - val_loss: 7.8301 - val_mae: 1.9126 - val_mse: 7.8301\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6154 - mae: 1.3421 - mse: 3.6154 - val_loss: 8.0054 - val_mae: 1.8995 - val_mse: 8.0054\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6179 - mae: 1.3364 - mse: 3.6179 - val_loss: 7.9879 - val_mae: 1.9014 - val_mse: 7.9879\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6773 - mae: 1.3602 - mse: 3.6773 - val_loss: 8.0224 - val_mae: 1.8983 - val_mse: 8.0224\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5064 - mae: 1.3206 - mse: 3.5064 - val_loss: 7.9554 - val_mae: 1.9163 - val_mse: 7.9554\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5026 - mae: 1.3216 - mse: 3.5026 - val_loss: 7.9077 - val_mae: 1.9211 - val_mse: 7.9077\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5315 - mae: 1.3256 - mse: 3.5315 - val_loss: 8.2034 - val_mae: 1.9720 - val_mse: 8.2034\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5812 - mae: 1.3258 - mse: 3.5812 - val_loss: 7.9676 - val_mae: 1.8803 - val_mse: 7.9676\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7548 - mae: 1.3526 - mse: 3.7548 - val_loss: 7.8106 - val_mae: 1.8884 - val_mse: 7.8106\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3751 - mae: 1.3377 - mse: 3.3751 - val_loss: 8.0060 - val_mae: 1.9540 - val_mse: 8.0060\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4922 - mae: 1.3197 - mse: 3.4922 - val_loss: 8.1877 - val_mae: 1.9271 - val_mse: 8.1877\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4557 - mae: 1.2979 - mse: 3.4557 - val_loss: 8.7706 - val_mae: 1.9955 - val_mse: 8.7706\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7180 - mae: 1.3552 - mse: 3.7180 - val_loss: 7.9709 - val_mae: 1.8766 - val_mse: 7.9709\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4655 - mae: 1.3031 - mse: 3.4655 - val_loss: 8.4489 - val_mae: 1.9185 - val_mse: 8.4489\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6574 - mae: 1.3454 - mse: 3.6574 - val_loss: 7.6703 - val_mae: 1.8856 - val_mse: 7.6703\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3810 - mae: 1.2885 - mse: 3.3810 - val_loss: 8.1415 - val_mae: 1.9044 - val_mse: 8.1415\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5559 - mae: 1.3249 - mse: 3.5559 - val_loss: 8.3519 - val_mae: 1.9352 - val_mse: 8.3519\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6274 - mae: 1.3829 - mse: 3.6274 - val_loss: 7.9346 - val_mae: 1.9261 - val_mse: 7.9346\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4089 - mae: 1.2909 - mse: 3.4089 - val_loss: 7.7132 - val_mae: 1.8832 - val_mse: 7.7132\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6429 - mae: 1.3280 - mse: 3.6429 - val_loss: 7.6253 - val_mae: 1.8754 - val_mse: 7.6253\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3379 - mae: 1.2798 - mse: 3.3379 - val_loss: 7.8483 - val_mae: 1.9166 - val_mse: 7.8483\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5974 - mae: 1.3477 - mse: 3.5974 - val_loss: 7.6733 - val_mae: 1.8581 - val_mse: 7.6733\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3933 - mae: 1.2960 - mse: 3.3933 - val_loss: 7.9417 - val_mae: 1.9461 - val_mse: 7.9417\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4341 - mae: 1.2837 - mse: 3.4341 - val_loss: 8.1716 - val_mae: 1.9051 - val_mse: 8.1716\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3835 - mae: 1.3064 - mse: 3.3835 - val_loss: 8.0420 - val_mae: 1.9587 - val_mse: 8.0420\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4987 - mae: 1.3244 - mse: 3.4987 - val_loss: 7.9711 - val_mae: 1.9336 - val_mse: 7.9711\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3822 - mae: 1.2806 - mse: 3.3822 - val_loss: 7.6697 - val_mae: 1.8806 - val_mse: 7.6697\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7161 - mae: 1.3840 - mse: 3.7161 - val_loss: 7.9175 - val_mae: 1.9255 - val_mse: 7.9175\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3825 - mae: 1.3026 - mse: 3.3825 - val_loss: 8.1458 - val_mae: 2.0179 - val_mse: 8.1458\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4208 - mae: 1.2867 - mse: 3.4208 - val_loss: 7.8355 - val_mae: 1.9048 - val_mse: 7.8355\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4635 - mae: 1.3098 - mse: 3.4635 - val_loss: 8.0803 - val_mae: 1.9437 - val_mse: 8.0803\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6370 - mae: 1.3434 - mse: 3.6370 - val_loss: 8.1422 - val_mae: 1.9113 - val_mse: 8.1422\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5066 - mae: 1.3173 - mse: 3.5066 - val_loss: 8.0147 - val_mae: 1.9442 - val_mse: 8.0147\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3906 - mae: 1.2681 - mse: 3.3906 - val_loss: 7.9614 - val_mae: 1.8944 - val_mse: 7.9614\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.5703 - mae: 1.3446 - mse: 3.5703 - val_loss: 8.3199 - val_mae: 1.9165 - val_mse: 8.3199\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4283 - mae: 1.3161 - mse: 3.4283 - val_loss: 8.7008 - val_mae: 1.9897 - val_mse: 8.7008\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5256 - mae: 1.3095 - mse: 3.5256 - val_loss: 7.6964 - val_mae: 1.8899 - val_mse: 7.6964\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3675 - mae: 1.3081 - mse: 3.3675 - val_loss: 7.8528 - val_mae: 1.8861 - val_mse: 7.8528\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3407 - mae: 1.3029 - mse: 3.3407 - val_loss: 8.1324 - val_mae: 1.9479 - val_mse: 8.1324\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4092 - mae: 1.2864 - mse: 3.4092 - val_loss: 8.2722 - val_mae: 1.8953 - val_mse: 8.2722\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4959 - mae: 1.3149 - mse: 3.4959 - val_loss: 8.0481 - val_mae: 1.9203 - val_mse: 8.0481\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4219 - mae: 1.2962 - mse: 3.4219 - val_loss: 8.1422 - val_mae: 1.9505 - val_mse: 8.1422\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4187 - mae: 1.2890 - mse: 3.4187 - val_loss: 7.8588 - val_mae: 1.8950 - val_mse: 7.8588\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4165 - mae: 1.2981 - mse: 3.4165 - val_loss: 8.2972 - val_mae: 1.9979 - val_mse: 8.2972\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5939 - mae: 1.3515 - mse: 3.5939 - val_loss: 7.9495 - val_mae: 1.8987 - val_mse: 7.9495\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3055 - mae: 1.2958 - mse: 3.3055 - val_loss: 7.9523 - val_mae: 1.9353 - val_mse: 7.9523\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3721 - mae: 1.2614 - mse: 3.3721 - val_loss: 7.8668 - val_mae: 1.9403 - val_mse: 7.8668\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4889 - mae: 1.3050 - mse: 3.4889 - val_loss: 7.9045 - val_mae: 1.9089 - val_mse: 7.9045\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3673 - mae: 1.2797 - mse: 3.3673 - val_loss: 8.2355 - val_mae: 1.9588 - val_mse: 8.2355\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2941 - mae: 1.2834 - mse: 3.2941 - val_loss: 7.8437 - val_mae: 1.9346 - val_mse: 7.8437\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4291 - mae: 1.2745 - mse: 3.4291 - val_loss: 8.4933 - val_mae: 1.9535 - val_mse: 8.4933\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6100 - mae: 1.3279 - mse: 3.6100 - val_loss: 7.7109 - val_mae: 1.8951 - val_mse: 7.7109\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3178 - mae: 1.2850 - mse: 3.3178 - val_loss: 7.5609 - val_mae: 1.8765 - val_mse: 7.5609\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6794 - mae: 1.3470 - mse: 3.6794 - val_loss: 7.5937 - val_mae: 1.8744 - val_mse: 7.5937\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2727 - mae: 1.2671 - mse: 3.2727 - val_loss: 7.7284 - val_mae: 1.8704 - val_mse: 7.7284\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3281 - mae: 1.2821 - mse: 3.3281 - val_loss: 7.8552 - val_mae: 1.9279 - val_mse: 7.8552\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2030 - mae: 1.2578 - mse: 3.2030 - val_loss: 8.0730 - val_mae: 1.9223 - val_mse: 8.0730\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5646 - mae: 1.3249 - mse: 3.5646 - val_loss: 8.1228 - val_mae: 1.9563 - val_mse: 8.1228\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4133 - mae: 1.2719 - mse: 3.4133 - val_loss: 7.8380 - val_mae: 1.9242 - val_mse: 7.8380\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4260 - mae: 1.2908 - mse: 3.4260 - val_loss: 8.0351 - val_mae: 1.9165 - val_mse: 8.0351\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3063 - mae: 1.2691 - mse: 3.3063 - val_loss: 7.6440 - val_mae: 1.8909 - val_mse: 7.6440\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3404 - mae: 1.2636 - mse: 3.3404 - val_loss: 7.9274 - val_mae: 1.9076 - val_mse: 7.9274\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1855 - mae: 1.2583 - mse: 3.1855 - val_loss: 8.2697 - val_mae: 1.9977 - val_mse: 8.2697\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5078 - mae: 1.2884 - mse: 3.5078 - val_loss: 8.1076 - val_mae: 1.9701 - val_mse: 8.1076\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3058 - mae: 1.2667 - mse: 3.3058 - val_loss: 8.1207 - val_mae: 1.9022 - val_mse: 8.1207\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2094 - mae: 1.2444 - mse: 3.2094 - val_loss: 8.3707 - val_mae: 1.9478 - val_mse: 8.3707\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2581 - mae: 1.3103 - mse: 3.2581 - val_loss: 8.1567 - val_mae: 2.0196 - val_mse: 8.1567\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4740 - mae: 1.2911 - mse: 3.4740 - val_loss: 8.5263 - val_mae: 1.9642 - val_mse: 8.5263\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2455 - mae: 1.2607 - mse: 3.2455 - val_loss: 7.8220 - val_mae: 1.9055 - val_mse: 7.8220\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2886 - mae: 1.2517 - mse: 3.2886 - val_loss: 8.0907 - val_mae: 1.9950 - val_mse: 8.0907\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3554 - mae: 1.2759 - mse: 3.3554 - val_loss: 7.6152 - val_mae: 1.8821 - val_mse: 7.6152\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4219 - mae: 1.2888 - mse: 3.4219 - val_loss: 8.2098 - val_mae: 1.9032 - val_mse: 8.2098\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2506 - mae: 1.2393 - mse: 3.2506 - val_loss: 7.8885 - val_mae: 1.8842 - val_mse: 7.8885\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2613 - mae: 1.2564 - mse: 3.2613 - val_loss: 9.0571 - val_mae: 2.0386 - val_mse: 9.0571\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2116 - mae: 1.2717 - mse: 3.2116 - val_loss: 8.1501 - val_mae: 1.9298 - val_mse: 8.1501\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3335 - mae: 1.2524 - mse: 3.3335 - val_loss: 7.8445 - val_mae: 1.9180 - val_mse: 7.8445\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3317 - mae: 1.2423 - mse: 3.3317 - val_loss: 8.0566 - val_mae: 1.9539 - val_mse: 8.0566\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2013 - mae: 1.2542 - mse: 3.2013 - val_loss: 8.1441 - val_mae: 1.9585 - val_mse: 8.1441\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3264 - mae: 1.2410 - mse: 3.3264 - val_loss: 8.0624 - val_mae: 1.9534 - val_mse: 8.0624\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2963 - mae: 1.2587 - mse: 3.2963 - val_loss: 8.0370 - val_mae: 1.9524 - val_mse: 8.0370\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4240 - mae: 1.2840 - mse: 3.4240 - val_loss: 7.8400 - val_mae: 1.8927 - val_mse: 7.8400\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3171 - mae: 1.2620 - mse: 3.3171 - val_loss: 8.0389 - val_mae: 1.9397 - val_mse: 8.0389\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1352 - mae: 1.2673 - mse: 3.1352 - val_loss: 8.4031 - val_mae: 1.9969 - val_mse: 8.4031\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2203 - mae: 1.2373 - mse: 3.2203 - val_loss: 8.3179 - val_mae: 1.9835 - val_mse: 8.3179\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2046 - mae: 1.2357 - mse: 3.2046 - val_loss: 8.1112 - val_mae: 1.9869 - val_mse: 8.1112\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2266 - mae: 1.2809 - mse: 3.2266 - val_loss: 7.9747 - val_mae: 1.9705 - val_mse: 7.9747\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1462 - mae: 1.2390 - mse: 3.1462 - val_loss: 9.1225 - val_mae: 2.0484 - val_mse: 9.1225\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2529 - mae: 1.3051 - mse: 3.2529 - val_loss: 7.9827 - val_mae: 1.9475 - val_mse: 7.9827\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1919 - mae: 1.2389 - mse: 3.1919 - val_loss: 7.7918 - val_mae: 1.9162 - val_mse: 7.7918\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2775 - mae: 1.2748 - mse: 3.2775 - val_loss: 7.6909 - val_mae: 1.9013 - val_mse: 7.6909\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2564 - mae: 1.2741 - mse: 3.2564 - val_loss: 7.9498 - val_mae: 1.9095 - val_mse: 7.9498\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2149 - mae: 1.2390 - mse: 3.2149 - val_loss: 7.5583 - val_mae: 1.8830 - val_mse: 7.5583\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2786 - mae: 1.2646 - mse: 3.2786 - val_loss: 7.6932 - val_mae: 1.8925 - val_mse: 7.6932\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2184 - mae: 1.2426 - mse: 3.2184 - val_loss: 7.8341 - val_mae: 1.9130 - val_mse: 7.8341\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2105 - mae: 1.2331 - mse: 3.2105 - val_loss: 8.0775 - val_mae: 1.9362 - val_mse: 8.0775\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1749 - mae: 1.2669 - mse: 3.1749 - val_loss: 7.8893 - val_mae: 1.9184 - val_mse: 7.8893\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1863 - mae: 1.2301 - mse: 3.1863 - val_loss: 8.2975 - val_mae: 1.9601 - val_mse: 8.2975\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3203 - mae: 1.2452 - mse: 3.3203 - val_loss: 7.7757 - val_mae: 1.9313 - val_mse: 7.7757\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2380 - mae: 1.2365 - mse: 3.2380 - val_loss: 8.2361 - val_mae: 1.9979 - val_mse: 8.2361\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1287 - mae: 1.2453 - mse: 3.1287 - val_loss: 8.3996 - val_mae: 1.9310 - val_mse: 8.3996\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0579 - mae: 1.2350 - mse: 3.0579 - val_loss: 7.9131 - val_mae: 1.9134 - val_mse: 7.9131\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.3646 - mae: 1.2980 - mse: 3.3646 - val_loss: 7.6942 - val_mae: 1.8770 - val_mse: 7.6942\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2289 - mae: 1.2560 - mse: 3.2289 - val_loss: 8.1838 - val_mae: 1.9374 - val_mse: 8.1838\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1150 - mae: 1.1957 - mse: 3.1150 - val_loss: 7.9553 - val_mae: 1.9318 - val_mse: 7.9553\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0310 - mae: 1.2299 - mse: 3.0310 - val_loss: 7.9605 - val_mae: 1.9235 - val_mse: 7.9605\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3096 - mae: 1.2556 - mse: 3.3096 - val_loss: 7.8301 - val_mae: 1.9274 - val_mse: 7.8301\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3863 - mae: 1.3182 - mse: 3.3863 - val_loss: 7.8545 - val_mae: 1.9192 - val_mse: 7.8545\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0574 - mae: 1.2049 - mse: 3.0574 - val_loss: 7.5984 - val_mae: 1.8815 - val_mse: 7.5984\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0832 - mae: 1.2111 - mse: 3.0832 - val_loss: 7.9010 - val_mae: 1.9464 - val_mse: 7.9010\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0042 - mae: 1.2097 - mse: 3.0042 - val_loss: 8.2803 - val_mae: 1.9553 - val_mse: 8.2803\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2774 - mae: 1.2588 - mse: 3.2774 - val_loss: 8.5751 - val_mae: 1.9806 - val_mse: 8.5751\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.2582 - mae: 1.2519 - mse: 3.2582 - val_loss: 7.9729 - val_mae: 1.9099 - val_mse: 7.9729\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9849 - mae: 1.2139 - mse: 2.9849 - val_loss: 8.3928 - val_mae: 1.9970 - val_mse: 8.3928\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3206 - mae: 1.2633 - mse: 3.3206 - val_loss: 8.3194 - val_mae: 1.9591 - val_mse: 8.3194\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0497 - mae: 1.1979 - mse: 3.0497 - val_loss: 9.1909 - val_mae: 2.0966 - val_mse: 9.1909\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3583 - mae: 1.2809 - mse: 3.3583 - val_loss: 9.0637 - val_mae: 2.0681 - val_mse: 9.0637\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1061 - mae: 1.2265 - mse: 3.1061 - val_loss: 7.8738 - val_mae: 1.9218 - val_mse: 7.8738\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0345 - mae: 1.2223 - mse: 3.0345 - val_loss: 7.9362 - val_mae: 1.9154 - val_mse: 7.9362\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0826 - mae: 1.1976 - mse: 3.0826 - val_loss: 8.0323 - val_mae: 1.9403 - val_mse: 8.0323\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1102 - mae: 1.2186 - mse: 3.1102 - val_loss: 8.7363 - val_mae: 2.0867 - val_mse: 8.7363\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2419 - mae: 1.2600 - mse: 3.2419 - val_loss: 7.9073 - val_mae: 1.9339 - val_mse: 7.9073\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9833 - mae: 1.1845 - mse: 2.9833 - val_loss: 8.4258 - val_mae: 1.9504 - val_mse: 8.4258\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0378 - mae: 1.2208 - mse: 3.0378 - val_loss: 7.9709 - val_mae: 1.9601 - val_mse: 7.9709\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2158 - mae: 1.2552 - mse: 3.2158 - val_loss: 8.3272 - val_mae: 1.9970 - val_mse: 8.3272\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1006 - mae: 1.2122 - mse: 3.1006 - val_loss: 8.7648 - val_mae: 2.0816 - val_mse: 8.7648\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0297 - mae: 1.1926 - mse: 3.0297 - val_loss: 9.1311 - val_mae: 2.0582 - val_mse: 9.1311\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1476 - mae: 1.2540 - mse: 3.1476 - val_loss: 7.9324 - val_mae: 1.9379 - val_mse: 7.9324\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9887 - mae: 1.2039 - mse: 2.9887 - val_loss: 7.8522 - val_mae: 1.9166 - val_mse: 7.8522\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0572 - mae: 1.1904 - mse: 3.0572 - val_loss: 8.2969 - val_mae: 2.0261 - val_mse: 8.2969\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0961 - mae: 1.2559 - mse: 3.0961 - val_loss: 7.6551 - val_mae: 1.8686 - val_mse: 7.6551\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9804 - mae: 1.1885 - mse: 2.9804 - val_loss: 7.9147 - val_mae: 1.9158 - val_mse: 7.9147\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3122 - mae: 1.2326 - mse: 3.3122 - val_loss: 7.6886 - val_mae: 1.9273 - val_mse: 7.6886\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0465 - mae: 1.2475 - mse: 3.0465 - val_loss: 7.9014 - val_mae: 1.9163 - val_mse: 7.9014\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.1357 - mae: 1.2558 - mse: 3.1357 - val_loss: 7.8951 - val_mae: 1.9594 - val_mse: 7.8951\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1530 - mae: 1.2356 - mse: 3.1530 - val_loss: 8.1263 - val_mae: 1.9406 - val_mse: 8.1263\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0793 - mae: 1.2183 - mse: 3.0793 - val_loss: 8.4439 - val_mae: 1.9983 - val_mse: 8.4439\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2041 - mae: 1.2599 - mse: 3.2041 - val_loss: 8.0142 - val_mae: 1.9466 - val_mse: 8.0142\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0081 - mae: 1.2152 - mse: 3.0081 - val_loss: 8.4998 - val_mae: 1.9713 - val_mse: 8.4998\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9861 - mae: 1.2011 - mse: 2.9861 - val_loss: 8.4472 - val_mae: 1.9749 - val_mse: 8.4472\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0286 - mae: 1.2126 - mse: 3.0286 - val_loss: 7.8735 - val_mae: 1.9234 - val_mse: 7.8735\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0506 - mae: 1.2406 - mse: 3.0506 - val_loss: 7.8850 - val_mae: 1.9622 - val_mse: 7.8850\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9993 - mae: 1.1798 - mse: 2.9993 - val_loss: 8.8599 - val_mae: 2.0304 - val_mse: 8.8599\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1040 - mae: 1.2275 - mse: 3.1040 - val_loss: 7.7873 - val_mae: 1.8957 - val_mse: 7.7873\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8543 - mae: 1.1882 - mse: 2.8543 - val_loss: 8.2237 - val_mae: 1.9660 - val_mse: 8.2237\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0265 - mae: 1.2066 - mse: 3.0265 - val_loss: 8.2003 - val_mae: 1.9827 - val_mse: 8.2003\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9396 - mae: 1.1658 - mse: 2.9396 - val_loss: 8.0385 - val_mae: 1.9287 - val_mse: 8.0385\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1929 - mae: 1.2755 - mse: 3.1929 - val_loss: 7.9707 - val_mae: 1.9560 - val_mse: 7.9707\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1127 - mae: 1.1876 - mse: 3.1127 - val_loss: 8.0875 - val_mae: 1.9552 - val_mse: 8.0875\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1272 - mae: 1.2252 - mse: 3.1272 - val_loss: 7.9204 - val_mae: 1.9287 - val_mse: 7.9204\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8913 - mae: 1.1846 - mse: 2.8913 - val_loss: 8.2291 - val_mae: 1.9780 - val_mse: 8.2291\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0871 - mae: 1.2244 - mse: 3.0871 - val_loss: 8.2416 - val_mae: 1.9268 - val_mse: 8.2416\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1807 - mae: 1.2363 - mse: 3.1807 - val_loss: 8.0609 - val_mae: 1.9675 - val_mse: 8.0609\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1220 - mae: 1.2024 - mse: 3.1220 - val_loss: 8.0246 - val_mae: 1.9624 - val_mse: 8.0246\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9837 - mae: 1.1937 - mse: 2.9837 - val_loss: 7.9061 - val_mae: 1.9321 - val_mse: 7.9061\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0414 - mae: 1.2098 - mse: 3.0414 - val_loss: 7.7195 - val_mae: 1.9306 - val_mse: 7.7195\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1066 - mae: 1.2273 - mse: 3.1066 - val_loss: 8.3128 - val_mae: 2.0013 - val_mse: 8.3128\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0124 - mae: 1.2087 - mse: 3.0124 - val_loss: 8.0995 - val_mae: 1.9183 - val_mse: 8.0995\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8450 - mae: 1.1447 - mse: 2.8450 - val_loss: 8.1821 - val_mae: 1.9641 - val_mse: 8.1821\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0145 - mae: 1.1868 - mse: 3.0145 - val_loss: 9.1063 - val_mae: 2.0498 - val_mse: 9.1063\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0423 - mae: 1.2353 - mse: 3.0423 - val_loss: 7.9638 - val_mae: 1.9150 - val_mse: 7.9638\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9368 - mae: 1.1936 - mse: 2.9368 - val_loss: 8.2229 - val_mae: 2.0303 - val_mse: 8.2229\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9206 - mae: 1.1838 - mse: 2.9206 - val_loss: 8.0220 - val_mae: 1.9448 - val_mse: 8.0220\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0146 - mae: 1.1976 - mse: 3.0146 - val_loss: 7.9298 - val_mae: 1.9282 - val_mse: 7.9298\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8419 - mae: 1.1576 - mse: 2.8419 - val_loss: 7.8376 - val_mae: 1.9599 - val_mse: 7.8376\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9882 - mae: 1.1956 - mse: 2.9882 - val_loss: 8.0543 - val_mae: 1.9603 - val_mse: 8.0543\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.9968 - mae: 1.2015 - mse: 2.9968 - val_loss: 7.8834 - val_mae: 1.9369 - val_mse: 7.8834\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1444 - mae: 1.2097 - mse: 3.1444 - val_loss: 7.9152 - val_mae: 1.9257 - val_mse: 7.9152\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0965 - mae: 1.2258 - mse: 3.0965 - val_loss: 7.9627 - val_mae: 1.9485 - val_mse: 7.9627\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0763 - mae: 1.1977 - mse: 3.0763 - val_loss: 7.9124 - val_mae: 1.9604 - val_mse: 7.9124\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9935 - mae: 1.2136 - mse: 2.9935 - val_loss: 7.8256 - val_mae: 1.9344 - val_mse: 7.8256\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9001 - mae: 1.1811 - mse: 2.9001 - val_loss: 8.1660 - val_mae: 1.9971 - val_mse: 8.1660\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9305 - mae: 1.1970 - mse: 2.9305 - val_loss: 8.2144 - val_mae: 1.9756 - val_mse: 8.2144\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1691 - mae: 1.2346 - mse: 3.1691 - val_loss: 8.3203 - val_mae: 2.0012 - val_mse: 8.3203\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9156 - mae: 1.1682 - mse: 2.9156 - val_loss: 7.9643 - val_mae: 1.9310 - val_mse: 7.9643\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9473 - mae: 1.1996 - mse: 2.9473 - val_loss: 8.1030 - val_mae: 1.9673 - val_mse: 8.1030\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9124 - mae: 1.1698 - mse: 2.9124 - val_loss: 7.9185 - val_mae: 1.9413 - val_mse: 7.9185\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8412 - mae: 1.1650 - mse: 2.8412 - val_loss: 8.5387 - val_mae: 1.9740 - val_mse: 8.5387\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2690 - mae: 1.2784 - mse: 3.2690 - val_loss: 7.8547 - val_mae: 1.9331 - val_mse: 7.8547\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8679 - mae: 1.1660 - mse: 2.8679 - val_loss: 8.6446 - val_mae: 1.9944 - val_mse: 8.6446\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8286 - mae: 1.1655 - mse: 2.8286 - val_loss: 7.8920 - val_mae: 1.9430 - val_mse: 7.8920\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8484 - mae: 1.1658 - mse: 2.8484 - val_loss: 8.6361 - val_mae: 1.9748 - val_mse: 8.6361\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9847 - mae: 1.2333 - mse: 2.9847 - val_loss: 8.0595 - val_mae: 1.9903 - val_mse: 8.0595\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9628 - mae: 1.1998 - mse: 2.9628 - val_loss: 8.6279 - val_mae: 1.9722 - val_mse: 8.6279\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0223 - mae: 1.2051 - mse: 3.0223 - val_loss: 7.8350 - val_mae: 1.9020 - val_mse: 7.8350\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8575 - mae: 1.1678 - mse: 2.8575 - val_loss: 8.3050 - val_mae: 1.9774 - val_mse: 8.3050\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8956 - mae: 1.1951 - mse: 2.8956 - val_loss: 7.8553 - val_mae: 1.9077 - val_mse: 7.8553\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7813 - mae: 1.1633 - mse: 2.7813 - val_loss: 8.1948 - val_mae: 1.9190 - val_mse: 8.1948\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8588 - mae: 1.1899 - mse: 2.8588 - val_loss: 8.2862 - val_mae: 1.9995 - val_mse: 8.2862\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.9514 - mae: 1.1520 - mse: 2.9514 - val_loss: 7.7192 - val_mae: 1.9068 - val_mse: 7.7192\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9558 - mae: 1.1721 - mse: 2.9558 - val_loss: 9.1608 - val_mae: 2.0668 - val_mse: 9.1608\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8154 - mae: 1.1691 - mse: 2.8154 - val_loss: 8.0416 - val_mae: 1.9587 - val_mse: 8.0416\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8814 - mae: 1.1502 - mse: 2.8814 - val_loss: 8.6865 - val_mae: 1.9973 - val_mse: 8.6865\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1113 - mae: 1.2360 - mse: 3.1113 - val_loss: 7.8337 - val_mae: 1.9142 - val_mse: 7.8337\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8701 - mae: 1.1599 - mse: 2.8701 - val_loss: 7.8193 - val_mae: 1.9028 - val_mse: 7.8193\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8258 - mae: 1.1499 - mse: 2.8258 - val_loss: 8.0380 - val_mae: 1.9053 - val_mse: 8.0380\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9526 - mae: 1.1857 - mse: 2.9526 - val_loss: 7.9694 - val_mae: 1.9640 - val_mse: 7.9694\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9186 - mae: 1.1701 - mse: 2.9186 - val_loss: 8.2435 - val_mae: 2.0136 - val_mse: 8.2435\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8342 - mae: 1.1718 - mse: 2.8342 - val_loss: 8.0945 - val_mae: 1.9237 - val_mse: 8.0945\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8398 - mae: 1.1258 - mse: 2.8398 - val_loss: 8.1913 - val_mae: 1.9161 - val_mse: 8.1913\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8200 - mae: 1.1471 - mse: 2.8200 - val_loss: 8.5760 - val_mae: 2.1404 - val_mse: 8.5760\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9271 - mae: 1.1963 - mse: 2.9271 - val_loss: 8.0542 - val_mae: 1.9773 - val_mse: 8.0542\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7763 - mae: 1.1560 - mse: 2.7763 - val_loss: 7.9486 - val_mae: 1.9680 - val_mse: 7.9486\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9173 - mae: 1.1592 - mse: 2.9173 - val_loss: 8.0289 - val_mae: 1.9697 - val_mse: 8.0289\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8664 - mae: 1.1713 - mse: 2.8664 - val_loss: 8.0535 - val_mae: 1.9928 - val_mse: 8.0535\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8351 - mae: 1.1696 - mse: 2.8351 - val_loss: 8.3785 - val_mae: 1.9531 - val_mse: 8.3785\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0844 - mae: 1.2020 - mse: 3.0844 - val_loss: 8.1213 - val_mae: 1.9475 - val_mse: 8.1213\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.7632 - mae: 1.1413 - mse: 2.7632 - val_loss: 8.6179 - val_mae: 2.1174 - val_mse: 8.6179\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.8911 - mae: 1.1725 - mse: 2.8911 - val_loss: 8.5752 - val_mae: 1.9817 - val_mse: 8.5752\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7564 - mae: 1.1704 - mse: 2.7564 - val_loss: 8.4760 - val_mae: 2.0412 - val_mse: 8.4760\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0652 - mae: 1.1995 - mse: 3.0652 - val_loss: 7.9397 - val_mae: 1.9359 - val_mse: 7.9397\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8097 - mae: 1.1617 - mse: 2.8097 - val_loss: 8.5700 - val_mae: 1.9747 - val_mse: 8.5700\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8201 - mae: 1.1489 - mse: 2.8201 - val_loss: 8.6141 - val_mae: 2.0261 - val_mse: 8.6141\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7485 - mae: 1.1244 - mse: 2.7485 - val_loss: 9.1027 - val_mae: 2.0221 - val_mse: 9.1027\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9513 - mae: 1.1883 - mse: 2.9513 - val_loss: 7.9881 - val_mae: 1.9380 - val_mse: 7.9881\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7171 - mae: 1.1174 - mse: 2.7171 - val_loss: 8.4428 - val_mae: 2.0596 - val_mse: 8.4428\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8836 - mae: 1.1511 - mse: 2.8836 - val_loss: 8.2112 - val_mae: 1.9427 - val_mse: 8.2112\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.0778 - mae: 1.2109 - mse: 3.0778 - val_loss: 8.0567 - val_mae: 1.9510 - val_mse: 8.0567\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6953 - mae: 1.1076 - mse: 2.6953 - val_loss: 8.7316 - val_mae: 2.0102 - val_mse: 8.7316\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8772 - mae: 1.1675 - mse: 2.8772 - val_loss: 8.2020 - val_mae: 1.9424 - val_mse: 8.2020\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8125 - mae: 1.1442 - mse: 2.8125 - val_loss: 8.8977 - val_mae: 2.0429 - val_mse: 8.8977\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8436 - mae: 1.1448 - mse: 2.8436 - val_loss: 8.2943 - val_mae: 2.0130 - val_mse: 8.2943\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8386 - mae: 1.1780 - mse: 2.8386 - val_loss: 8.3248 - val_mae: 2.0200 - val_mse: 8.3248\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8062 - mae: 1.1363 - mse: 2.8062 - val_loss: 8.1714 - val_mae: 1.9738 - val_mse: 8.1714\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7611 - mae: 1.1215 - mse: 2.7611 - val_loss: 8.4307 - val_mae: 1.9455 - val_mse: 8.4307\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9822 - mae: 1.1762 - mse: 2.9822 - val_loss: 8.0594 - val_mae: 1.9362 - val_mse: 8.0594\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7811 - mae: 1.1518 - mse: 2.7811 - val_loss: 8.3100 - val_mae: 1.9744 - val_mse: 8.3100\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6854 - mae: 1.0996 - mse: 2.6854 - val_loss: 7.7621 - val_mae: 1.9243 - val_mse: 7.7621\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6981 - mae: 1.1239 - mse: 2.6981 - val_loss: 8.1853 - val_mae: 2.0085 - val_mse: 8.1853\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8197 - mae: 1.1992 - mse: 2.8197 - val_loss: 8.2356 - val_mae: 1.9483 - val_mse: 8.2356\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7994 - mae: 1.1608 - mse: 2.7994 - val_loss: 8.3879 - val_mae: 2.0782 - val_mse: 8.3879\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8321 - mae: 1.1694 - mse: 2.8321 - val_loss: 7.7474 - val_mae: 1.9064 - val_mse: 7.7474\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6542 - mae: 1.0961 - mse: 2.6542 - val_loss: 8.3868 - val_mae: 1.9585 - val_mse: 8.3868\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8616 - mae: 1.1739 - mse: 2.8616 - val_loss: 7.7551 - val_mae: 1.9340 - val_mse: 7.7551\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9091 - mae: 1.1384 - mse: 2.9091 - val_loss: 8.0308 - val_mae: 1.9539 - val_mse: 8.0308\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8550 - mae: 1.1760 - mse: 2.8550 - val_loss: 8.2342 - val_mae: 1.9672 - val_mse: 8.2342\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7630 - mae: 1.1322 - mse: 2.7630 - val_loss: 8.2516 - val_mae: 1.9629 - val_mse: 8.2516\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.6979 - mae: 1.1353 - mse: 2.6979 - val_loss: 8.2188 - val_mae: 2.0008 - val_mse: 8.2188\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6201 - mae: 1.1075 - mse: 2.6201 - val_loss: 8.0360 - val_mae: 1.9323 - val_mse: 8.0360\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6534 - mae: 1.1246 - mse: 2.6534 - val_loss: 7.8966 - val_mae: 1.9297 - val_mse: 7.8966\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8773 - mae: 1.1612 - mse: 2.8773 - val_loss: 8.0741 - val_mae: 1.9863 - val_mse: 8.0741\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9607 - mae: 1.1705 - mse: 2.9607 - val_loss: 8.0717 - val_mae: 1.9658 - val_mse: 8.0717\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6189 - mae: 1.1137 - mse: 2.6189 - val_loss: 8.6288 - val_mae: 2.0583 - val_mse: 8.6288\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6392 - mae: 1.1364 - mse: 2.6392 - val_loss: 7.9677 - val_mae: 1.9171 - val_mse: 7.9677\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8206 - mae: 1.1265 - mse: 2.8206 - val_loss: 8.0072 - val_mae: 1.9776 - val_mse: 8.0072\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7500 - mae: 1.1768 - mse: 2.7500 - val_loss: 7.8401 - val_mae: 1.9290 - val_mse: 7.8401\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7171 - mae: 1.1192 - mse: 2.7171 - val_loss: 8.4553 - val_mae: 2.0394 - val_mse: 8.4553\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6460 - mae: 1.1104 - mse: 2.6460 - val_loss: 8.0395 - val_mae: 1.9713 - val_mse: 8.0395\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8494 - mae: 1.1386 - mse: 2.8494 - val_loss: 8.0643 - val_mae: 1.9306 - val_mse: 8.0643\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7260 - mae: 1.1476 - mse: 2.7260 - val_loss: 8.1393 - val_mae: 2.0174 - val_mse: 8.1393\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9975 - mae: 1.1814 - mse: 2.9975 - val_loss: 8.2310 - val_mae: 1.9553 - val_mse: 8.2310\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6725 - mae: 1.1103 - mse: 2.6725 - val_loss: 8.2629 - val_mae: 1.9607 - val_mse: 8.2629\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7986 - mae: 1.1336 - mse: 2.7986 - val_loss: 8.0159 - val_mae: 1.9511 - val_mse: 8.0159\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6942 - mae: 1.1378 - mse: 2.6942 - val_loss: 8.5373 - val_mae: 1.9844 - val_mse: 8.5373\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6389 - mae: 1.0844 - mse: 2.6389 - val_loss: 8.2639 - val_mae: 2.0098 - val_mse: 8.2639\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6304 - mae: 1.1333 - mse: 2.6304 - val_loss: 8.0654 - val_mae: 1.9782 - val_mse: 8.0654\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6889 - mae: 1.1133 - mse: 2.6889 - val_loss: 8.5394 - val_mae: 1.9805 - val_mse: 8.5394\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7002 - mae: 1.1288 - mse: 2.7002 - val_loss: 8.1835 - val_mae: 1.9335 - val_mse: 8.1835\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7981 - mae: 1.1370 - mse: 2.7981 - val_loss: 8.6607 - val_mae: 1.9912 - val_mse: 8.6607\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7665 - mae: 1.1244 - mse: 2.7665 - val_loss: 8.3762 - val_mae: 1.9936 - val_mse: 8.3762\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6163 - mae: 1.1085 - mse: 2.6163 - val_loss: 8.3903 - val_mae: 1.9737 - val_mse: 8.3903\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6667 - mae: 1.1129 - mse: 2.6667 - val_loss: 8.2557 - val_mae: 1.9626 - val_mse: 8.2557\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7391 - mae: 1.1178 - mse: 2.7391 - val_loss: 8.2500 - val_mae: 1.9364 - val_mse: 8.2500\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7116 - mae: 1.1287 - mse: 2.7116 - val_loss: 8.5846 - val_mae: 2.1086 - val_mse: 8.5846\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8699 - mae: 1.1559 - mse: 2.8699 - val_loss: 8.1654 - val_mae: 1.9518 - val_mse: 8.1654\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7722 - mae: 1.1408 - mse: 2.7722 - val_loss: 8.1127 - val_mae: 1.9718 - val_mse: 8.1127\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7005 - mae: 1.1068 - mse: 2.7005 - val_loss: 8.1853 - val_mae: 1.9589 - val_mse: 8.1853\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6579 - mae: 1.1041 - mse: 2.6579 - val_loss: 8.3761 - val_mae: 1.9782 - val_mse: 8.3761\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8143 - mae: 1.1672 - mse: 2.8143 - val_loss: 7.9381 - val_mae: 1.9240 - val_mse: 7.9381\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5118 - mae: 1.0666 - mse: 2.5118 - val_loss: 8.5080 - val_mae: 2.0421 - val_mse: 8.5080\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5970 - mae: 1.1129 - mse: 2.5970 - val_loss: 8.4114 - val_mae: 2.0042 - val_mse: 8.4114\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7530 - mae: 1.1271 - mse: 2.7530 - val_loss: 9.4359 - val_mae: 2.0814 - val_mse: 9.4359\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7047 - mae: 1.0880 - mse: 2.7047 - val_loss: 8.8746 - val_mae: 2.0789 - val_mse: 8.8746\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6276 - mae: 1.1201 - mse: 2.6276 - val_loss: 8.1875 - val_mae: 1.9968 - val_mse: 8.1875\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6274 - mae: 1.1161 - mse: 2.6274 - val_loss: 8.3742 - val_mae: 2.0096 - val_mse: 8.3742\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7837 - mae: 1.1355 - mse: 2.7837 - val_loss: 8.0461 - val_mae: 1.9713 - val_mse: 8.0461\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6830 - mae: 1.1163 - mse: 2.6830 - val_loss: 8.1144 - val_mae: 1.9501 - val_mse: 8.1144\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5349 - mae: 1.0716 - mse: 2.5349 - val_loss: 8.2693 - val_mae: 1.9715 - val_mse: 8.2693\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7834 - mae: 1.1394 - mse: 2.7834 - val_loss: 8.6954 - val_mae: 2.0227 - val_mse: 8.6954\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6420 - mae: 1.0994 - mse: 2.6420 - val_loss: 8.0531 - val_mae: 1.9474 - val_mse: 8.0531\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5142 - mae: 1.0819 - mse: 2.5142 - val_loss: 8.5810 - val_mae: 1.9999 - val_mse: 8.5810\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6493 - mae: 1.1173 - mse: 2.6493 - val_loss: 8.5474 - val_mae: 2.0204 - val_mse: 8.5474\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6187 - mae: 1.1126 - mse: 2.6187 - val_loss: 8.6140 - val_mae: 2.0116 - val_mse: 8.6140\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7451 - mae: 1.1333 - mse: 2.7451 - val_loss: 8.0375 - val_mae: 1.9412 - val_mse: 8.0375\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5027 - mae: 1.0845 - mse: 2.5027 - val_loss: 8.0304 - val_mae: 1.9954 - val_mse: 8.0304\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.9058 - mae: 1.1924 - mse: 2.9058 - val_loss: 8.1212 - val_mae: 1.9693 - val_mse: 8.1212\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5817 - mae: 1.1010 - mse: 2.5817 - val_loss: 8.5817 - val_mae: 2.0214 - val_mse: 8.5817\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6739 - mae: 1.1151 - mse: 2.6739 - val_loss: 8.7498 - val_mae: 2.0066 - val_mse: 8.7498\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5529 - mae: 1.0732 - mse: 2.5529 - val_loss: 8.1745 - val_mae: 1.9791 - val_mse: 8.1745\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5202 - mae: 1.1038 - mse: 2.5202 - val_loss: 8.1901 - val_mae: 1.9931 - val_mse: 8.1901\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4367 - mae: 1.0787 - mse: 2.4367 - val_loss: 8.5428 - val_mae: 2.0404 - val_mse: 8.5428\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5649 - mae: 1.1071 - mse: 2.5649 - val_loss: 8.3904 - val_mae: 1.9830 - val_mse: 8.3904\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6423 - mae: 1.1163 - mse: 2.6423 - val_loss: 8.4004 - val_mae: 1.9645 - val_mse: 8.4004\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5373 - mae: 1.0861 - mse: 2.5373 - val_loss: 8.1978 - val_mae: 1.9777 - val_mse: 8.1978\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5848 - mae: 1.1096 - mse: 2.5848 - val_loss: 8.3275 - val_mae: 1.9539 - val_mse: 8.3275\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5566 - mae: 1.0910 - mse: 2.5566 - val_loss: 8.7867 - val_mae: 2.0163 - val_mse: 8.7867\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5100 - mae: 1.0791 - mse: 2.5100 - val_loss: 8.5335 - val_mae: 2.0106 - val_mse: 8.5335\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8619 - mae: 1.1607 - mse: 2.8619 - val_loss: 8.3469 - val_mae: 2.0020 - val_mse: 8.3469\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5064 - mae: 1.0441 - mse: 2.5064 - val_loss: 8.3429 - val_mae: 1.9934 - val_mse: 8.3429\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6452 - mae: 1.1396 - mse: 2.6452 - val_loss: 8.7799 - val_mae: 2.1165 - val_mse: 8.7799\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5588 - mae: 1.0590 - mse: 2.5588 - val_loss: 9.2683 - val_mae: 2.1110 - val_mse: 9.2683\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4178 - mae: 1.0772 - mse: 2.4178 - val_loss: 8.7323 - val_mae: 2.0277 - val_mse: 8.7323\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5527 - mae: 1.0832 - mse: 2.5527 - val_loss: 8.5194 - val_mae: 1.9860 - val_mse: 8.5194\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5356 - mae: 1.0726 - mse: 2.5356 - val_loss: 8.5134 - val_mae: 1.9608 - val_mse: 8.5134\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.4964 - mae: 1.0566 - mse: 2.4964 - val_loss: 8.2874 - val_mae: 2.0329 - val_mse: 8.2874\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5928 - mae: 1.1007 - mse: 2.5928 - val_loss: 9.6702 - val_mae: 2.1087 - val_mse: 9.6702\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5995 - mae: 1.1260 - mse: 2.5995 - val_loss: 8.7845 - val_mae: 2.1097 - val_mse: 8.7845\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6404 - mae: 1.0837 - mse: 2.6404 - val_loss: 8.6260 - val_mae: 1.9898 - val_mse: 8.6260\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5504 - mae: 1.0965 - mse: 2.5504 - val_loss: 8.3613 - val_mae: 1.9716 - val_mse: 8.3613\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5511 - mae: 1.0893 - mse: 2.5511 - val_loss: 8.7395 - val_mae: 2.0144 - val_mse: 8.7395\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6740 - mae: 1.0817 - mse: 2.6740 - val_loss: 8.4409 - val_mae: 1.9638 - val_mse: 8.4409\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5771 - mae: 1.1108 - mse: 2.5771 - val_loss: 8.9046 - val_mae: 2.0455 - val_mse: 8.9046\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5211 - mae: 1.0501 - mse: 2.5211 - val_loss: 9.3657 - val_mae: 2.1515 - val_mse: 9.3657\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.5483 - mae: 1.1028 - mse: 2.5483 - val_loss: 8.2378 - val_mae: 1.9750 - val_mse: 8.2378\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6569 - mae: 1.0681 - mse: 2.6569 - val_loss: 8.8324 - val_mae: 2.0421 - val_mse: 8.8324\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4718 - mae: 1.0558 - mse: 2.4718 - val_loss: 8.9330 - val_mae: 2.0480 - val_mse: 8.9330\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6158 - mae: 1.0973 - mse: 2.6158 - val_loss: 8.5973 - val_mae: 2.0019 - val_mse: 8.5973\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7736 - mae: 1.1384 - mse: 2.7736 - val_loss: 8.4222 - val_mae: 2.0011 - val_mse: 8.4222\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5915 - mae: 1.1043 - mse: 2.5915 - val_loss: 8.8169 - val_mae: 2.0159 - val_mse: 8.8169\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5053 - mae: 1.0592 - mse: 2.5053 - val_loss: 8.7716 - val_mae: 2.0259 - val_mse: 8.7716\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4204 - mae: 1.0630 - mse: 2.4204 - val_loss: 8.8046 - val_mae: 2.0746 - val_mse: 8.8046\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6521 - mae: 1.1052 - mse: 2.6521 - val_loss: 8.6088 - val_mae: 1.9972 - val_mse: 8.6088\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4391 - mae: 1.0420 - mse: 2.4391 - val_loss: 8.6369 - val_mae: 2.0198 - val_mse: 8.6369\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5449 - mae: 1.0643 - mse: 2.5449 - val_loss: 8.6097 - val_mae: 2.0123 - val_mse: 8.6097\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6212 - mae: 1.1295 - mse: 2.6212 - val_loss: 8.7584 - val_mae: 2.0640 - val_mse: 8.7584\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5429 - mae: 1.1123 - mse: 2.5429 - val_loss: 8.6973 - val_mae: 2.0430 - val_mse: 8.6973\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3949 - mae: 1.0293 - mse: 2.3949 - val_loss: 8.7175 - val_mae: 2.0035 - val_mse: 8.7175\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4686 - mae: 1.0719 - mse: 2.4686 - val_loss: 9.3804 - val_mae: 2.0705 - val_mse: 9.3804\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6540 - mae: 1.0995 - mse: 2.6540 - val_loss: 8.6005 - val_mae: 2.0029 - val_mse: 8.6005\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4602 - mae: 1.0633 - mse: 2.4602 - val_loss: 8.4345 - val_mae: 2.0353 - val_mse: 8.4345\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4979 - mae: 1.0772 - mse: 2.4979 - val_loss: 8.7836 - val_mae: 2.0144 - val_mse: 8.7836\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4381 - mae: 1.0649 - mse: 2.4381 - val_loss: 8.8720 - val_mae: 2.0841 - val_mse: 8.8720\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5278 - mae: 1.0604 - mse: 2.5278 - val_loss: 8.4446 - val_mae: 1.9794 - val_mse: 8.4446\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5160 - mae: 1.1218 - mse: 2.5160 - val_loss: 8.9251 - val_mae: 2.0794 - val_mse: 8.9251\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6887 - mae: 1.1274 - mse: 2.6887 - val_loss: 8.2833 - val_mae: 1.9897 - val_mse: 8.2833\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4523 - mae: 1.0665 - mse: 2.4523 - val_loss: 8.6336 - val_mae: 2.0283 - val_mse: 8.6336\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4144 - mae: 1.0476 - mse: 2.4144 - val_loss: 8.9583 - val_mae: 2.0369 - val_mse: 8.9583\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3840 - mae: 1.0431 - mse: 2.3840 - val_loss: 8.6008 - val_mae: 2.0017 - val_mse: 8.6008\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3651 - mae: 1.0872 - mse: 2.3651 - val_loss: 9.9407 - val_mae: 2.1454 - val_mse: 9.9407\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5456 - mae: 1.0558 - mse: 2.5456 - val_loss: 8.4358 - val_mae: 1.9639 - val_mse: 8.4358\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3826 - mae: 1.0474 - mse: 2.3826 - val_loss: 9.7240 - val_mae: 2.1005 - val_mse: 9.7240\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7616 - mae: 1.1287 - mse: 2.7616 - val_loss: 8.6342 - val_mae: 2.0350 - val_mse: 8.6342\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3972 - mae: 1.0617 - mse: 2.3972 - val_loss: 8.5147 - val_mae: 2.0225 - val_mse: 8.5147\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4622 - mae: 1.0541 - mse: 2.4622 - val_loss: 8.4556 - val_mae: 2.0240 - val_mse: 8.4556\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4863 - mae: 1.0786 - mse: 2.4863 - val_loss: 8.5943 - val_mae: 2.0967 - val_mse: 8.5943\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3110 - mae: 1.0310 - mse: 2.3110 - val_loss: 10.4902 - val_mae: 2.1914 - val_mse: 10.4902\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5443 - mae: 1.1164 - mse: 2.5443 - val_loss: 8.6911 - val_mae: 2.0531 - val_mse: 8.6911\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6202 - mae: 1.0843 - mse: 2.6202 - val_loss: 8.5318 - val_mae: 2.0206 - val_mse: 8.5318\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5346 - mae: 1.1073 - mse: 2.5346 - val_loss: 8.4190 - val_mae: 1.9929 - val_mse: 8.4190\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4234 - mae: 1.0597 - mse: 2.4234 - val_loss: 8.8408 - val_mae: 2.0851 - val_mse: 8.8408\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6068 - mae: 1.1199 - mse: 2.6068 - val_loss: 8.7415 - val_mae: 2.0371 - val_mse: 8.7415\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.3573 - mae: 1.0203 - mse: 2.3573 - val_loss: 8.9850 - val_mae: 2.1167 - val_mse: 8.9850\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4487 - mae: 1.0395 - mse: 2.4487 - val_loss: 8.8161 - val_mae: 2.0458 - val_mse: 8.8161\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5525 - mae: 1.0914 - mse: 2.5525 - val_loss: 8.5942 - val_mae: 2.0074 - val_mse: 8.5942\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4414 - mae: 1.0461 - mse: 2.4414 - val_loss: 8.8153 - val_mae: 2.0263 - val_mse: 8.8153\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3382 - mae: 1.0439 - mse: 2.3382 - val_loss: 9.2187 - val_mae: 2.0549 - val_mse: 9.2187\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6422 - mae: 1.1325 - mse: 2.6422 - val_loss: 8.6941 - val_mae: 1.9728 - val_mse: 8.6941\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5325 - mae: 1.0752 - mse: 2.5325 - val_loss: 9.1281 - val_mae: 2.0570 - val_mse: 9.1281\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4215 - mae: 1.0803 - mse: 2.4215 - val_loss: 8.5327 - val_mae: 1.9902 - val_mse: 8.5327\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4814 - mae: 1.0586 - mse: 2.4814 - val_loss: 9.2148 - val_mae: 2.1636 - val_mse: 9.2148\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3954 - mae: 1.0559 - mse: 2.3954 - val_loss: 9.0653 - val_mae: 2.0481 - val_mse: 9.0653\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4370 - mae: 1.0777 - mse: 2.4370 - val_loss: 9.0727 - val_mae: 2.0209 - val_mse: 9.0727\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3871 - mae: 1.0523 - mse: 2.3871 - val_loss: 8.7441 - val_mae: 2.0098 - val_mse: 8.7441\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4215 - mae: 1.0880 - mse: 2.4215 - val_loss: 8.6131 - val_mae: 1.9965 - val_mse: 8.6131\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6558 - mae: 1.0956 - mse: 2.6558 - val_loss: 9.0307 - val_mae: 2.0645 - val_mse: 9.0307\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3315 - mae: 1.0830 - mse: 2.3315 - val_loss: 8.8276 - val_mae: 2.0212 - val_mse: 8.8276\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3488 - mae: 1.0574 - mse: 2.3488 - val_loss: 8.8809 - val_mae: 2.0624 - val_mse: 8.8809\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4532 - mae: 1.0685 - mse: 2.4532 - val_loss: 8.8023 - val_mae: 2.0658 - val_mse: 8.8023\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4470 - mae: 1.0616 - mse: 2.4470 - val_loss: 8.3049 - val_mae: 2.0104 - val_mse: 8.3049\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3592 - mae: 1.0390 - mse: 2.3592 - val_loss: 9.0767 - val_mae: 2.1862 - val_mse: 9.0767\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5218 - mae: 1.0975 - mse: 2.5218 - val_loss: 8.7586 - val_mae: 2.0606 - val_mse: 8.7586\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4209 - mae: 1.0287 - mse: 2.4209 - val_loss: 9.0841 - val_mae: 2.1184 - val_mse: 9.0841\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3167 - mae: 1.0259 - mse: 2.3167 - val_loss: 8.8506 - val_mae: 2.0698 - val_mse: 8.8506\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4735 - mae: 1.0692 - mse: 2.4735 - val_loss: 8.9771 - val_mae: 2.0493 - val_mse: 8.9771\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1792 - mae: 0.9844 - mse: 2.1792 - val_loss: 9.3552 - val_mae: 2.1247 - val_mse: 9.3552\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7401 - mae: 1.1221 - mse: 2.7401 - val_loss: 9.0356 - val_mae: 2.1149 - val_mse: 9.0356\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4205 - mae: 1.0495 - mse: 2.4205 - val_loss: 8.8058 - val_mae: 2.0032 - val_mse: 8.8058\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2890 - mae: 1.0300 - mse: 2.2890 - val_loss: 8.6697 - val_mae: 2.0262 - val_mse: 8.6697\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4083 - mae: 1.0476 - mse: 2.4083 - val_loss: 8.8935 - val_mae: 2.0738 - val_mse: 8.8935\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4311 - mae: 1.0461 - mse: 2.4311 - val_loss: 9.2940 - val_mae: 2.1038 - val_mse: 9.2940\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4554 - mae: 1.0629 - mse: 2.4554 - val_loss: 8.9131 - val_mae: 2.0145 - val_mse: 8.9131\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4541 - mae: 1.0639 - mse: 2.4541 - val_loss: 8.9851 - val_mae: 2.0196 - val_mse: 8.9851\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4823 - mae: 1.0862 - mse: 2.4823 - val_loss: 9.5412 - val_mae: 2.1051 - val_mse: 9.5412\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3252 - mae: 1.0575 - mse: 2.3252 - val_loss: 9.0372 - val_mae: 2.0923 - val_mse: 9.0372\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3961 - mae: 1.0255 - mse: 2.3961 - val_loss: 8.8366 - val_mae: 2.0601 - val_mse: 8.8366\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3156 - mae: 1.0394 - mse: 2.3156 - val_loss: 9.4185 - val_mae: 2.0640 - val_mse: 9.4185\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3865 - mae: 1.0541 - mse: 2.3865 - val_loss: 8.9621 - val_mae: 2.0138 - val_mse: 8.9621\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5140 - mae: 1.0562 - mse: 2.5140 - val_loss: 8.6784 - val_mae: 2.0073 - val_mse: 8.6784\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1636 - mae: 1.0061 - mse: 2.1636 - val_loss: 9.4414 - val_mae: 2.0648 - val_mse: 9.4414\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3558 - mae: 1.0320 - mse: 2.3558 - val_loss: 9.3204 - val_mae: 2.1120 - val_mse: 9.3204\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3259 - mae: 1.0232 - mse: 2.3259 - val_loss: 8.7567 - val_mae: 2.0309 - val_mse: 8.7567\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5726 - mae: 1.0782 - mse: 2.5726 - val_loss: 8.9239 - val_mae: 2.1719 - val_mse: 8.9239\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3313 - mae: 1.0537 - mse: 2.3313 - val_loss: 9.1497 - val_mae: 2.1034 - val_mse: 9.1497\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3403 - mae: 1.0321 - mse: 2.3403 - val_loss: 8.8853 - val_mae: 2.0448 - val_mse: 8.8853\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2860 - mae: 1.0140 - mse: 2.2860 - val_loss: 10.1161 - val_mae: 2.1590 - val_mse: 10.1161\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3791 - mae: 1.0847 - mse: 2.3791 - val_loss: 10.9923 - val_mae: 2.2725 - val_mse: 10.9923\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5874 - mae: 1.0973 - mse: 2.5874 - val_loss: 9.1175 - val_mae: 2.0702 - val_mse: 9.1175\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2438 - mae: 1.0277 - mse: 2.2438 - val_loss: 8.9848 - val_mae: 2.0653 - val_mse: 8.9848\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2231 - mae: 1.0085 - mse: 2.2231 - val_loss: 8.2303 - val_mae: 1.9571 - val_mse: 8.2303\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3621 - mae: 1.0255 - mse: 2.3621 - val_loss: 9.2665 - val_mae: 2.0597 - val_mse: 9.2665\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2655 - mae: 1.0256 - mse: 2.2655 - val_loss: 9.0927 - val_mae: 2.0406 - val_mse: 9.0927\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3053 - mae: 1.0553 - mse: 2.3053 - val_loss: 8.5544 - val_mae: 2.0049 - val_mse: 8.5544\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4647 - mae: 1.0426 - mse: 2.4647 - val_loss: 8.9862 - val_mae: 2.0689 - val_mse: 8.9862\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1719 - mae: 0.9959 - mse: 2.1719 - val_loss: 9.3671 - val_mae: 2.1199 - val_mse: 9.3671\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4000 - mae: 1.0376 - mse: 2.4000 - val_loss: 9.3556 - val_mae: 2.2056 - val_mse: 9.3556\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3875 - mae: 1.1131 - mse: 2.3875 - val_loss: 9.1415 - val_mae: 2.1093 - val_mse: 9.1415\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1663 - mae: 0.9856 - mse: 2.1663 - val_loss: 9.6140 - val_mae: 2.1965 - val_mse: 9.6140\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4085 - mae: 1.0545 - mse: 2.4085 - val_loss: 9.0368 - val_mae: 2.0083 - val_mse: 9.0368\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3547 - mae: 1.0735 - mse: 2.3547 - val_loss: 8.8582 - val_mae: 2.0768 - val_mse: 8.8582\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2131 - mae: 1.0305 - mse: 2.2131 - val_loss: 8.6060 - val_mae: 2.0042 - val_mse: 8.6060\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4180 - mae: 1.0959 - mse: 2.4180 - val_loss: 8.9031 - val_mae: 2.0249 - val_mse: 8.9031\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3029 - mae: 1.0303 - mse: 2.3029 - val_loss: 9.4457 - val_mae: 2.0639 - val_mse: 9.4457\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2756 - mae: 1.0301 - mse: 2.2756 - val_loss: 9.2895 - val_mae: 2.0893 - val_mse: 9.2895\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3168 - mae: 1.0485 - mse: 2.3168 - val_loss: 8.9594 - val_mae: 2.0011 - val_mse: 8.9594\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2068 - mae: 1.0138 - mse: 2.2068 - val_loss: 9.0114 - val_mae: 2.1237 - val_mse: 9.0114\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2464 - mae: 1.0154 - mse: 2.2464 - val_loss: 9.3917 - val_mae: 2.1803 - val_mse: 9.3917\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4469 - mae: 1.0657 - mse: 2.4469 - val_loss: 8.9805 - val_mae: 2.0606 - val_mse: 8.9805\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3971 - mae: 1.0162 - mse: 2.3971 - val_loss: 9.1347 - val_mae: 2.0715 - val_mse: 9.1347\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2407 - mae: 0.9862 - mse: 2.2407 - val_loss: 8.5847 - val_mae: 1.9655 - val_mse: 8.5847\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3138 - mae: 1.0847 - mse: 2.3138 - val_loss: 9.1732 - val_mae: 2.0765 - val_mse: 9.1732\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1276 - mae: 0.9981 - mse: 2.1276 - val_loss: 8.9980 - val_mae: 2.0611 - val_mse: 8.9980\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3610 - mae: 1.0454 - mse: 2.3610 - val_loss: 9.2461 - val_mae: 2.0966 - val_mse: 9.2461\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2922 - mae: 1.0002 - mse: 2.2922 - val_loss: 9.0031 - val_mae: 2.0992 - val_mse: 9.0031\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2999 - mae: 1.0051 - mse: 2.2999 - val_loss: 9.2388 - val_mae: 2.0583 - val_mse: 9.2388\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2400 - mae: 1.0468 - mse: 2.2400 - val_loss: 9.2891 - val_mae: 2.0972 - val_mse: 9.2891\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3662 - mae: 1.0331 - mse: 2.3662 - val_loss: 9.5505 - val_mae: 2.1732 - val_mse: 9.5505\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1977 - mae: 0.9893 - mse: 2.1977 - val_loss: 9.3461 - val_mae: 2.1216 - val_mse: 9.3461\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3301 - mae: 1.0282 - mse: 2.3301 - val_loss: 8.8454 - val_mae: 2.0152 - val_mse: 8.8454\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2715 - mae: 1.0011 - mse: 2.2715 - val_loss: 8.9899 - val_mae: 2.0636 - val_mse: 8.9899\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0909 - mae: 0.9808 - mse: 2.0909 - val_loss: 10.2471 - val_mae: 2.1568 - val_mse: 10.2471\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3986 - mae: 1.0629 - mse: 2.3986 - val_loss: 9.2219 - val_mae: 2.1102 - val_mse: 9.2219\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1600 - mae: 1.0141 - mse: 2.1600 - val_loss: 10.2728 - val_mae: 2.1849 - val_mse: 10.2728\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2077 - mae: 1.0061 - mse: 2.2077 - val_loss: 9.1720 - val_mae: 2.0913 - val_mse: 9.1720\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1458 - mae: 0.9987 - mse: 2.1458 - val_loss: 8.9397 - val_mae: 2.0825 - val_mse: 8.9397\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1961 - mae: 0.9921 - mse: 2.1961 - val_loss: 9.2927 - val_mae: 2.1690 - val_mse: 9.2927\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1860 - mae: 1.0055 - mse: 2.1860 - val_loss: 9.5481 - val_mae: 2.1107 - val_mse: 9.5481\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4264 - mae: 1.0594 - mse: 2.4264 - val_loss: 9.3154 - val_mae: 2.1202 - val_mse: 9.3154\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2848 - mae: 1.0323 - mse: 2.2848 - val_loss: 9.0966 - val_mae: 2.1344 - val_mse: 9.0966\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2300 - mae: 0.9975 - mse: 2.2300 - val_loss: 9.1254 - val_mae: 2.0617 - val_mse: 9.1254\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1182 - mae: 0.9973 - mse: 2.1182 - val_loss: 8.9544 - val_mae: 2.0033 - val_mse: 8.9544\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2172 - mae: 1.0281 - mse: 2.2172 - val_loss: 9.3299 - val_mae: 2.1324 - val_mse: 9.3299\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1720 - mae: 1.0100 - mse: 2.1720 - val_loss: 9.8839 - val_mae: 2.1078 - val_mse: 9.8839\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3839 - mae: 1.0508 - mse: 2.3839 - val_loss: 9.5447 - val_mae: 2.1076 - val_mse: 9.5447\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1909 - mae: 0.9896 - mse: 2.1909 - val_loss: 8.9027 - val_mae: 2.0328 - val_mse: 8.9027\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0759 - mae: 0.9835 - mse: 2.0759 - val_loss: 9.2130 - val_mae: 2.0893 - val_mse: 9.2130\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1496 - mae: 1.0262 - mse: 2.1496 - val_loss: 9.3522 - val_mae: 2.1254 - val_mse: 9.3522\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2138 - mae: 1.0438 - mse: 2.2138 - val_loss: 9.3821 - val_mae: 2.0830 - val_mse: 9.3821\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2294 - mae: 0.9716 - mse: 2.2294 - val_loss: 9.1723 - val_mae: 2.0966 - val_mse: 9.1723\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1513 - mae: 1.0023 - mse: 2.1513 - val_loss: 8.8370 - val_mae: 2.0542 - val_mse: 8.8370\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2050 - mae: 1.0185 - mse: 2.2050 - val_loss: 9.0772 - val_mae: 2.1206 - val_mse: 9.0772\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1408 - mae: 1.0081 - mse: 2.1408 - val_loss: 9.2961 - val_mae: 2.1454 - val_mse: 9.2961\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1311 - mae: 1.0110 - mse: 2.1311 - val_loss: 9.3765 - val_mae: 2.1219 - val_mse: 9.3765\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2049 - mae: 0.9992 - mse: 2.2049 - val_loss: 9.4725 - val_mae: 2.1122 - val_mse: 9.4725\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0797 - mae: 0.9834 - mse: 2.0797 - val_loss: 9.7667 - val_mae: 2.1743 - val_mse: 9.7667\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1908 - mae: 1.0345 - mse: 2.1908 - val_loss: 9.3891 - val_mae: 2.1217 - val_mse: 9.3891\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2100 - mae: 1.0035 - mse: 2.2100 - val_loss: 9.4741 - val_mae: 2.1771 - val_mse: 9.4741\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2151 - mae: 1.0058 - mse: 2.2151 - val_loss: 9.4028 - val_mae: 2.1218 - val_mse: 9.4028\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0045 - mae: 0.9628 - mse: 2.0045 - val_loss: 9.7546 - val_mae: 2.1360 - val_mse: 9.7546\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0462 - mae: 0.9707 - mse: 2.0462 - val_loss: 9.7971 - val_mae: 2.2003 - val_mse: 9.7971\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1623 - mae: 0.9689 - mse: 2.1623 - val_loss: 9.4522 - val_mae: 2.0957 - val_mse: 9.4522\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1692 - mae: 1.0015 - mse: 2.1692 - val_loss: 8.9617 - val_mae: 2.0635 - val_mse: 8.9617\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0822 - mae: 0.9618 - mse: 2.0822 - val_loss: 9.4245 - val_mae: 2.1397 - val_mse: 9.4245\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1177 - mae: 0.9987 - mse: 2.1177 - val_loss: 9.1786 - val_mae: 2.1151 - val_mse: 9.1786\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1939 - mae: 0.9813 - mse: 2.1939 - val_loss: 9.3319 - val_mae: 2.1540 - val_mse: 9.3319\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1788 - mae: 1.0434 - mse: 2.1788 - val_loss: 9.1878 - val_mae: 2.0895 - val_mse: 9.1878\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1159 - mae: 0.9749 - mse: 2.1159 - val_loss: 9.4949 - val_mae: 2.2093 - val_mse: 9.4949\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2871 - mae: 1.0075 - mse: 2.2871 - val_loss: 9.2688 - val_mae: 2.1134 - val_mse: 9.2688\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0501 - mae: 0.9750 - mse: 2.0501 - val_loss: 10.6332 - val_mae: 2.4106 - val_mse: 10.6332\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1040 - mae: 1.0130 - mse: 2.1040 - val_loss: 9.4187 - val_mae: 2.1491 - val_mse: 9.4187\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1050 - mae: 0.9897 - mse: 2.1050 - val_loss: 9.5139 - val_mae: 2.1152 - val_mse: 9.5139\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9841 - mae: 0.9764 - mse: 1.9841 - val_loss: 9.5922 - val_mae: 2.1127 - val_mse: 9.5922\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0479 - mae: 0.9892 - mse: 2.0479 - val_loss: 9.5536 - val_mae: 2.1693 - val_mse: 9.5536\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1382 - mae: 0.9836 - mse: 2.1382 - val_loss: 9.8975 - val_mae: 2.1295 - val_mse: 9.8975\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0966 - mae: 1.0035 - mse: 2.0966 - val_loss: 9.6187 - val_mae: 2.1677 - val_mse: 9.6187\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2229 - mae: 1.0074 - mse: 2.2229 - val_loss: 9.4312 - val_mae: 2.0954 - val_mse: 9.4312\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1137 - mae: 0.9723 - mse: 2.1137 - val_loss: 9.6444 - val_mae: 2.1093 - val_mse: 9.6444\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9374 - mae: 0.9780 - mse: 1.9374 - val_loss: 9.8370 - val_mae: 2.2759 - val_mse: 9.8370\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1774 - mae: 1.0142 - mse: 2.1774 - val_loss: 9.2625 - val_mae: 2.1188 - val_mse: 9.2625\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1887 - mae: 0.9874 - mse: 2.1887 - val_loss: 9.4124 - val_mae: 2.1245 - val_mse: 9.4124\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9650 - mae: 0.9263 - mse: 1.9650 - val_loss: 9.1602 - val_mae: 2.0868 - val_mse: 9.1602\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9715 - mae: 0.9486 - mse: 1.9715 - val_loss: 9.3208 - val_mae: 2.1278 - val_mse: 9.3208\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1134 - mae: 1.0051 - mse: 2.1134 - val_loss: 9.3283 - val_mae: 2.0985 - val_mse: 9.3283\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0877 - mae: 0.9860 - mse: 2.0877 - val_loss: 9.7483 - val_mae: 2.1331 - val_mse: 9.7483\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0790 - mae: 0.9825 - mse: 2.0790 - val_loss: 9.2835 - val_mae: 2.1027 - val_mse: 9.2835\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0868 - mae: 1.0004 - mse: 2.0868 - val_loss: 9.1778 - val_mae: 2.0576 - val_mse: 9.1778\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0715 - mae: 0.9811 - mse: 2.0715 - val_loss: 9.0335 - val_mae: 2.0369 - val_mse: 9.0335\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9914 - mae: 0.9573 - mse: 1.9914 - val_loss: 9.5783 - val_mae: 2.1549 - val_mse: 9.5783\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2062 - mae: 0.9945 - mse: 2.2062 - val_loss: 9.2875 - val_mae: 2.1002 - val_mse: 9.2875\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1299 - mae: 0.9734 - mse: 2.1299 - val_loss: 9.4494 - val_mae: 2.1340 - val_mse: 9.4494\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0770 - mae: 0.9864 - mse: 2.0770 - val_loss: 9.4294 - val_mae: 2.0923 - val_mse: 9.4294\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0433 - mae: 0.9632 - mse: 2.0433 - val_loss: 9.6837 - val_mae: 2.1495 - val_mse: 9.6837\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2467 - mae: 0.9873 - mse: 2.2467 - val_loss: 10.0009 - val_mae: 2.1496 - val_mse: 10.0009\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0399 - mae: 0.9983 - mse: 2.0399 - val_loss: 9.4514 - val_mae: 2.1510 - val_mse: 9.4514\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0061 - mae: 0.9667 - mse: 2.0061 - val_loss: 9.1343 - val_mae: 2.0917 - val_mse: 9.1343\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9140 - mae: 0.9193 - mse: 1.9140 - val_loss: 9.4800 - val_mae: 2.2089 - val_mse: 9.4800\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.1757 - mae: 0.9918 - mse: 2.1757 - val_loss: 9.7993 - val_mae: 2.1438 - val_mse: 9.7993\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9799 - mae: 0.9818 - mse: 1.9799 - val_loss: 9.5942 - val_mae: 2.1032 - val_mse: 9.5942\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0139 - mae: 0.9713 - mse: 2.0139 - val_loss: 10.1031 - val_mae: 2.2995 - val_mse: 10.1031\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9693 - mae: 0.9837 - mse: 1.9693 - val_loss: 9.5447 - val_mae: 2.1786 - val_mse: 9.5447\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0339 - mae: 0.9808 - mse: 2.0339 - val_loss: 10.2126 - val_mae: 2.2571 - val_mse: 10.2126\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0078 - mae: 0.9560 - mse: 2.0078 - val_loss: 9.5828 - val_mae: 2.1984 - val_mse: 9.5828\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9672 - mae: 0.9645 - mse: 1.9672 - val_loss: 9.0628 - val_mae: 2.0655 - val_mse: 9.0628\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8860 - mae: 0.9380 - mse: 1.8860 - val_loss: 9.6825 - val_mae: 2.1458 - val_mse: 9.6825\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3192 - mae: 1.0463 - mse: 2.3192 - val_loss: 9.3400 - val_mae: 2.0975 - val_mse: 9.3400\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9423 - mae: 0.9499 - mse: 1.9423 - val_loss: 9.5370 - val_mae: 2.1399 - val_mse: 9.5370\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2875 - mae: 1.0130 - mse: 2.2875 - val_loss: 9.4490 - val_mae: 2.1322 - val_mse: 9.4490\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9536 - mae: 0.9148 - mse: 1.9536 - val_loss: 9.5467 - val_mae: 2.1336 - val_mse: 9.5467\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1626 - mae: 1.0466 - mse: 2.1626 - val_loss: 9.1929 - val_mae: 2.0856 - val_mse: 9.1929\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9996 - mae: 0.9424 - mse: 1.9996 - val_loss: 9.4438 - val_mae: 2.1652 - val_mse: 9.4438\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0206 - mae: 0.9650 - mse: 2.0206 - val_loss: 9.3457 - val_mae: 2.1002 - val_mse: 9.3457\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9279 - mae: 0.9402 - mse: 1.9279 - val_loss: 9.7115 - val_mae: 2.1515 - val_mse: 9.7115\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9883 - mae: 0.9725 - mse: 1.9883 - val_loss: 9.8678 - val_mae: 2.1987 - val_mse: 9.8678\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0371 - mae: 0.9770 - mse: 2.0371 - val_loss: 9.5332 - val_mae: 2.1653 - val_mse: 9.5332\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0198 - mae: 0.9959 - mse: 2.0198 - val_loss: 9.7238 - val_mae: 2.1346 - val_mse: 9.7238\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9282 - mae: 0.9239 - mse: 1.9282 - val_loss: 10.2906 - val_mae: 2.2039 - val_mse: 10.2906\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1428 - mae: 0.9622 - mse: 2.1428 - val_loss: 9.5584 - val_mae: 2.1517 - val_mse: 9.5584\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0249 - mae: 0.9700 - mse: 2.0249 - val_loss: 10.3521 - val_mae: 2.2367 - val_mse: 10.3521\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9553 - mae: 0.9523 - mse: 1.9553 - val_loss: 9.3323 - val_mae: 2.1375 - val_mse: 9.3323\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9563 - mae: 0.9672 - mse: 1.9563 - val_loss: 9.5207 - val_mae: 2.1391 - val_mse: 9.5207\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8762 - mae: 0.9395 - mse: 1.8762 - val_loss: 9.7669 - val_mae: 2.1537 - val_mse: 9.7669\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1651 - mae: 1.0055 - mse: 2.1651 - val_loss: 9.4982 - val_mae: 2.0862 - val_mse: 9.4982\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9900 - mae: 0.9971 - mse: 1.9900 - val_loss: 9.6824 - val_mae: 2.1359 - val_mse: 9.6824\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0117 - mae: 0.9486 - mse: 2.0117 - val_loss: 9.8328 - val_mae: 2.1988 - val_mse: 9.8328\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0664 - mae: 1.0172 - mse: 2.0664 - val_loss: 9.9807 - val_mae: 2.1936 - val_mse: 9.9807\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9942 - mae: 0.9551 - mse: 1.9942 - val_loss: 9.9508 - val_mae: 2.2230 - val_mse: 9.9508\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9340 - mae: 0.9162 - mse: 1.9340 - val_loss: 9.9594 - val_mae: 2.1492 - val_mse: 9.9594\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9993 - mae: 0.9544 - mse: 1.9993 - val_loss: 9.5374 - val_mae: 2.1394 - val_mse: 9.5374\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9953 - mae: 0.9668 - mse: 1.9953 - val_loss: 10.2696 - val_mae: 2.2046 - val_mse: 10.2696\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0370 - mae: 0.9971 - mse: 2.0370 - val_loss: 9.7898 - val_mae: 2.1699 - val_mse: 9.7898\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9465 - mae: 0.9328 - mse: 1.9465 - val_loss: 9.3558 - val_mae: 2.1164 - val_mse: 9.3558\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2431 - mae: 1.0034 - mse: 2.2431 - val_loss: 9.6312 - val_mae: 2.2049 - val_mse: 9.6312\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8737 - mae: 0.9331 - mse: 1.8737 - val_loss: 9.3768 - val_mae: 2.1036 - val_mse: 9.3768\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9752 - mae: 0.9522 - mse: 1.9752 - val_loss: 9.9597 - val_mae: 2.2260 - val_mse: 9.9597\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0943 - mae: 0.9775 - mse: 2.0943 - val_loss: 9.5400 - val_mae: 2.1769 - val_mse: 9.5400\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8860 - mae: 0.9232 - mse: 1.8860 - val_loss: 9.5660 - val_mae: 2.1375 - val_mse: 9.5660\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8727 - mae: 0.9306 - mse: 1.8727 - val_loss: 9.6235 - val_mae: 2.1683 - val_mse: 9.6235\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1012 - mae: 0.9689 - mse: 2.1012 - val_loss: 9.9138 - val_mae: 2.2366 - val_mse: 9.9138\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8387 - mae: 0.9401 - mse: 1.8387 - val_loss: 9.2808 - val_mae: 2.0940 - val_mse: 9.2808\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9846 - mae: 0.9534 - mse: 1.9846 - val_loss: 9.7804 - val_mae: 2.1791 - val_mse: 9.7804\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0999 - mae: 1.0089 - mse: 2.0999 - val_loss: 9.8233 - val_mae: 2.2167 - val_mse: 9.8233\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9029 - mae: 0.9266 - mse: 1.9029 - val_loss: 9.6116 - val_mae: 2.1535 - val_mse: 9.6116\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8661 - mae: 0.9208 - mse: 1.8661 - val_loss: 9.8150 - val_mae: 2.1661 - val_mse: 9.8150\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0192 - mae: 0.9864 - mse: 2.0192 - val_loss: 9.6562 - val_mae: 2.1377 - val_mse: 9.6562\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0331 - mae: 0.9628 - mse: 2.0331 - val_loss: 10.0668 - val_mae: 2.1878 - val_mse: 10.0668\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8691 - mae: 0.9090 - mse: 1.8691 - val_loss: 9.5603 - val_mae: 2.1344 - val_mse: 9.5603\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0709 - mae: 0.9717 - mse: 2.0709 - val_loss: 9.7096 - val_mae: 2.1478 - val_mse: 9.7096\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8643 - mae: 0.9313 - mse: 1.8643 - val_loss: 10.1430 - val_mae: 2.2852 - val_mse: 10.1430\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0506 - mae: 1.0063 - mse: 2.0506 - val_loss: 9.7154 - val_mae: 2.1594 - val_mse: 9.7154\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9673 - mae: 0.9448 - mse: 1.9673 - val_loss: 9.7849 - val_mae: 2.1572 - val_mse: 9.7849\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7705 - mae: 0.9035 - mse: 1.7705 - val_loss: 10.2651 - val_mae: 2.2780 - val_mse: 10.2651\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8160 - mae: 0.9202 - mse: 1.8160 - val_loss: 10.2222 - val_mae: 2.1856 - val_mse: 10.2222\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8794 - mae: 0.9544 - mse: 1.8794 - val_loss: 9.6666 - val_mae: 2.1520 - val_mse: 9.6666\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9518 - mae: 0.9576 - mse: 1.9518 - val_loss: 9.9218 - val_mae: 2.2574 - val_mse: 9.9218\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0831 - mae: 1.0216 - mse: 2.0831 - val_loss: 9.6439 - val_mae: 2.1443 - val_mse: 9.6439\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7879 - mae: 0.9024 - mse: 1.7879 - val_loss: 10.1150 - val_mae: 2.2858 - val_mse: 10.1150\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8139 - mae: 0.9429 - mse: 1.8139 - val_loss: 9.6812 - val_mae: 2.1689 - val_mse: 9.6812\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9779 - mae: 0.9281 - mse: 1.9779 - val_loss: 9.7128 - val_mae: 2.2159 - val_mse: 9.7128\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8579 - mae: 0.9070 - mse: 1.8579 - val_loss: 10.0019 - val_mae: 2.2144 - val_mse: 10.0019\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9194 - mae: 0.9597 - mse: 1.9194 - val_loss: 9.8587 - val_mae: 2.2564 - val_mse: 9.8587\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8182 - mae: 0.9232 - mse: 1.8182 - val_loss: 10.0228 - val_mae: 2.2042 - val_mse: 10.0228\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9084 - mae: 0.9326 - mse: 1.9084 - val_loss: 10.0880 - val_mae: 2.2731 - val_mse: 10.0880\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9496 - mae: 0.9742 - mse: 1.9496 - val_loss: 9.6369 - val_mae: 2.1692 - val_mse: 9.6369\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8094 - mae: 0.8963 - mse: 1.8094 - val_loss: 9.4713 - val_mae: 2.1484 - val_mse: 9.4713\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9063 - mae: 0.9134 - mse: 1.9063 - val_loss: 9.9363 - val_mae: 2.1821 - val_mse: 9.9363\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8659 - mae: 0.9272 - mse: 1.8659 - val_loss: 10.1107 - val_mae: 2.2443 - val_mse: 10.1107\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9538 - mae: 0.9470 - mse: 1.9538 - val_loss: 9.9206 - val_mae: 2.2159 - val_mse: 9.9206\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9323 - mae: 0.9497 - mse: 1.9323 - val_loss: 10.4625 - val_mae: 2.3103 - val_mse: 10.4625\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0370 - mae: 0.9407 - mse: 2.0370 - val_loss: 9.6596 - val_mae: 2.1651 - val_mse: 9.6596\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8051 - mae: 0.9070 - mse: 1.8051 - val_loss: 10.7026 - val_mae: 2.2313 - val_mse: 10.7026\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9283 - mae: 0.9677 - mse: 1.9283 - val_loss: 10.1823 - val_mae: 2.1969 - val_mse: 10.1823\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9287 - mae: 0.9811 - mse: 1.9287 - val_loss: 9.8198 - val_mae: 2.1844 - val_mse: 9.8198\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7886 - mae: 0.8933 - mse: 1.7886 - val_loss: 9.7630 - val_mae: 2.1644 - val_mse: 9.7630\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8590 - mae: 0.9340 - mse: 1.8590 - val_loss: 9.8252 - val_mae: 2.1208 - val_mse: 9.8252\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8997 - mae: 0.9489 - mse: 1.8997 - val_loss: 10.2083 - val_mae: 2.2856 - val_mse: 10.2083\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8580 - mae: 0.9426 - mse: 1.8580 - val_loss: 9.7751 - val_mae: 2.1098 - val_mse: 9.7751\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8273 - mae: 0.9156 - mse: 1.8273 - val_loss: 10.2746 - val_mae: 2.2536 - val_mse: 10.2746\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7769 - mae: 0.9128 - mse: 1.7769 - val_loss: 10.1065 - val_mae: 2.2234 - val_mse: 10.1065\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8599 - mae: 0.9543 - mse: 1.8599 - val_loss: 9.5399 - val_mae: 2.1246 - val_mse: 9.5399\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8202 - mae: 0.9108 - mse: 1.8202 - val_loss: 9.7966 - val_mae: 2.1730 - val_mse: 9.7966\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0427 - mae: 0.9642 - mse: 2.0427 - val_loss: 10.0302 - val_mae: 2.2316 - val_mse: 10.0302\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7534 - mae: 0.9061 - mse: 1.7534 - val_loss: 9.6894 - val_mae: 2.1320 - val_mse: 9.6894\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9137 - mae: 0.9747 - mse: 1.9137 - val_loss: 9.8560 - val_mae: 2.1645 - val_mse: 9.8560\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8075 - mae: 0.9152 - mse: 1.8075 - val_loss: 9.3777 - val_mae: 2.0910 - val_mse: 9.3777\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8261 - mae: 0.9459 - mse: 1.8261 - val_loss: 9.8579 - val_mae: 2.1916 - val_mse: 9.8579\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8205 - mae: 0.9186 - mse: 1.8205 - val_loss: 9.8951 - val_mae: 2.2319 - val_mse: 9.8951\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9215 - mae: 0.9400 - mse: 1.9215 - val_loss: 9.7932 - val_mae: 2.1746 - val_mse: 9.7932\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8274 - mae: 0.9162 - mse: 1.8274 - val_loss: 10.1745 - val_mae: 2.2800 - val_mse: 10.1745\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8062 - mae: 0.9087 - mse: 1.8062 - val_loss: 10.3133 - val_mae: 2.2552 - val_mse: 10.3133\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0129 - mae: 0.9402 - mse: 2.0129 - val_loss: 10.0457 - val_mae: 2.1784 - val_mse: 10.0457\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7875 - mae: 0.8997 - mse: 1.7875 - val_loss: 9.7959 - val_mae: 2.1809 - val_mse: 9.7959\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1101 - mae: 0.9942 - mse: 2.1101 - val_loss: 10.1743 - val_mae: 2.2381 - val_mse: 10.1743\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7616 - mae: 0.9082 - mse: 1.7616 - val_loss: 10.4985 - val_mae: 2.2878 - val_mse: 10.4985\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7202 - mae: 0.8909 - mse: 1.7202 - val_loss: 9.6471 - val_mae: 2.1576 - val_mse: 9.6471\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7472 - mae: 0.9220 - mse: 1.7472 - val_loss: 9.7409 - val_mae: 2.1622 - val_mse: 9.7409\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8205 - mae: 0.8920 - mse: 1.8205 - val_loss: 9.9813 - val_mae: 2.1575 - val_mse: 9.9813\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8379 - mae: 0.9358 - mse: 1.8379 - val_loss: 9.7774 - val_mae: 2.1638 - val_mse: 9.7774\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7553 - mae: 0.9089 - mse: 1.7553 - val_loss: 10.9208 - val_mae: 2.3214 - val_mse: 10.9208\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9718 - mae: 0.9634 - mse: 1.9718 - val_loss: 10.2771 - val_mae: 2.2409 - val_mse: 10.2771\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7336 - mae: 0.8751 - mse: 1.7336 - val_loss: 10.6215 - val_mae: 2.2937 - val_mse: 10.6215\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9243 - mae: 0.9365 - mse: 1.9243 - val_loss: 9.9873 - val_mae: 2.1982 - val_mse: 9.9873\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7232 - mae: 0.8987 - mse: 1.7232 - val_loss: 10.2730 - val_mae: 2.3236 - val_mse: 10.2730\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7125 - mae: 0.8881 - mse: 1.7125 - val_loss: 10.1338 - val_mae: 2.2260 - val_mse: 10.1338\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8656 - mae: 0.9161 - mse: 1.8656 - val_loss: 9.9125 - val_mae: 2.1753 - val_mse: 9.9125\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7957 - mae: 0.9533 - mse: 1.7957 - val_loss: 9.7656 - val_mae: 2.1594 - val_mse: 9.7656\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8588 - mae: 0.9195 - mse: 1.8588 - val_loss: 10.0399 - val_mae: 2.1809 - val_mse: 10.0399\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7861 - mae: 0.9213 - mse: 1.7861 - val_loss: 10.0031 - val_mae: 2.1841 - val_mse: 10.0031\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7917 - mae: 0.9303 - mse: 1.7917 - val_loss: 9.9284 - val_mae: 2.1962 - val_mse: 9.9284\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7250 - mae: 0.8843 - mse: 1.7250 - val_loss: 10.4124 - val_mae: 2.2577 - val_mse: 10.4124\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7320 - mae: 0.8565 - mse: 1.7320 - val_loss: 10.4557 - val_mae: 2.3426 - val_mse: 10.4557\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8347 - mae: 0.9388 - mse: 1.8347 - val_loss: 10.8577 - val_mae: 2.2232 - val_mse: 10.8577\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9531 - mae: 0.9416 - mse: 1.9531 - val_loss: 9.7282 - val_mae: 2.1600 - val_mse: 9.7282\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6759 - mae: 0.8932 - mse: 1.6759 - val_loss: 10.6758 - val_mae: 2.3340 - val_mse: 10.6758\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8052 - mae: 0.9225 - mse: 1.8052 - val_loss: 10.2125 - val_mae: 2.2185 - val_mse: 10.2125\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6792 - mae: 0.8982 - mse: 1.6792 - val_loss: 10.3240 - val_mae: 2.2690 - val_mse: 10.3240\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8102 - mae: 0.9447 - mse: 1.8102 - val_loss: 10.2990 - val_mae: 2.2201 - val_mse: 10.2990\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0497 - mae: 0.9781 - mse: 2.0497 - val_loss: 10.3322 - val_mae: 2.2489 - val_mse: 10.3322\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6564 - mae: 0.8613 - mse: 1.6564 - val_loss: 10.1740 - val_mae: 2.2569 - val_mse: 10.1740\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8776 - mae: 0.9641 - mse: 1.8776 - val_loss: 9.8095 - val_mae: 2.1782 - val_mse: 9.8095\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7383 - mae: 0.9040 - mse: 1.7383 - val_loss: 9.7352 - val_mae: 2.1661 - val_mse: 9.7352\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7449 - mae: 0.8976 - mse: 1.7449 - val_loss: 10.2973 - val_mae: 2.2494 - val_mse: 10.2973\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8047 - mae: 0.9187 - mse: 1.8047 - val_loss: 9.7453 - val_mae: 2.1909 - val_mse: 9.7453\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7270 - mae: 0.9046 - mse: 1.7270 - val_loss: 10.4179 - val_mae: 2.2607 - val_mse: 10.4179\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8413 - mae: 0.9379 - mse: 1.8413 - val_loss: 9.8415 - val_mae: 2.1738 - val_mse: 9.8415\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7528 - mae: 0.9106 - mse: 1.7528 - val_loss: 10.1100 - val_mae: 2.2571 - val_mse: 10.1100\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7985 - mae: 0.9254 - mse: 1.7985 - val_loss: 9.9780 - val_mae: 2.1734 - val_mse: 9.9780\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9038 - mae: 0.9552 - mse: 1.9038 - val_loss: 9.7600 - val_mae: 2.1868 - val_mse: 9.7600\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7141 - mae: 0.8934 - mse: 1.7141 - val_loss: 10.1683 - val_mae: 2.2316 - val_mse: 10.1683\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8067 - mae: 0.9138 - mse: 1.8067 - val_loss: 9.9016 - val_mae: 2.1867 - val_mse: 9.9016\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8093 - mae: 0.9084 - mse: 1.8093 - val_loss: 9.6706 - val_mae: 2.1606 - val_mse: 9.6706\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6923 - mae: 0.8911 - mse: 1.6923 - val_loss: 9.8425 - val_mae: 2.2077 - val_mse: 9.8425\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6546 - mae: 0.8886 - mse: 1.6546 - val_loss: 10.2089 - val_mae: 2.2167 - val_mse: 10.2089\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8748 - mae: 0.9642 - mse: 1.8748 - val_loss: 9.5527 - val_mae: 2.1537 - val_mse: 9.5527\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5330 - mae: 0.8469 - mse: 1.5330 - val_loss: 11.3078 - val_mae: 2.2938 - val_mse: 11.3078\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0278 - mae: 0.9630 - mse: 2.0278 - val_loss: 10.3887 - val_mae: 2.2540 - val_mse: 10.3887\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7479 - mae: 0.9137 - mse: 1.7479 - val_loss: 10.4850 - val_mae: 2.3101 - val_mse: 10.4850\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6899 - mae: 0.8780 - mse: 1.6899 - val_loss: 10.2361 - val_mae: 2.2655 - val_mse: 10.2361\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6809 - mae: 0.8792 - mse: 1.6809 - val_loss: 10.2724 - val_mae: 2.2481 - val_mse: 10.2724\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6302 - mae: 0.8739 - mse: 1.6302 - val_loss: 10.8102 - val_mae: 2.3665 - val_mse: 10.8102\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0007 - mae: 1.0053 - mse: 2.0007 - val_loss: 10.1485 - val_mae: 2.2414 - val_mse: 10.1485\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6939 - mae: 0.8972 - mse: 1.6939 - val_loss: 10.2407 - val_mae: 2.2626 - val_mse: 10.2407\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5145 - mae: 0.8161 - mse: 1.5145 - val_loss: 10.0191 - val_mae: 2.2164 - val_mse: 10.0191\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7261 - mae: 0.8914 - mse: 1.7261 - val_loss: 10.7177 - val_mae: 2.2456 - val_mse: 10.7177\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7957 - mae: 0.9108 - mse: 1.7957 - val_loss: 10.1457 - val_mae: 2.2521 - val_mse: 10.1457\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7662 - mae: 0.8875 - mse: 1.7662 - val_loss: 10.1827 - val_mae: 2.2651 - val_mse: 10.1827\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6536 - mae: 0.8634 - mse: 1.6536 - val_loss: 10.2761 - val_mae: 2.2396 - val_mse: 10.2761\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6331 - mae: 0.8539 - mse: 1.6331 - val_loss: 10.3859 - val_mae: 2.2439 - val_mse: 10.3859\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6671 - mae: 0.8928 - mse: 1.6671 - val_loss: 9.8159 - val_mae: 2.1439 - val_mse: 9.8159\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7904 - mae: 0.9100 - mse: 1.7904 - val_loss: 9.9869 - val_mae: 2.1697 - val_mse: 9.9869\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7213 - mae: 0.8709 - mse: 1.7213 - val_loss: 10.1061 - val_mae: 2.2389 - val_mse: 10.1061\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6215 - mae: 0.8504 - mse: 1.6215 - val_loss: 10.2411 - val_mae: 2.1967 - val_mse: 10.2411\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6915 - mae: 0.8973 - mse: 1.6915 - val_loss: 10.4556 - val_mae: 2.2529 - val_mse: 10.4556\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7572 - mae: 0.9198 - mse: 1.7572 - val_loss: 10.0950 - val_mae: 2.2612 - val_mse: 10.0950\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5585 - mae: 0.8620 - mse: 1.5585 - val_loss: 10.4668 - val_mae: 2.2159 - val_mse: 10.4668\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8549 - mae: 0.9402 - mse: 1.8549 - val_loss: 10.5299 - val_mae: 2.2124 - val_mse: 10.5299\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6530 - mae: 0.8898 - mse: 1.6530 - val_loss: 10.2641 - val_mae: 2.2152 - val_mse: 10.2641\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6288 - mae: 0.8917 - mse: 1.6288 - val_loss: 10.7621 - val_mae: 2.2893 - val_mse: 10.7621\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5498 - mae: 0.8318 - mse: 1.5498 - val_loss: 10.4444 - val_mae: 2.2708 - val_mse: 10.4444\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5590 - mae: 0.8646 - mse: 1.5590 - val_loss: 10.5353 - val_mae: 2.2396 - val_mse: 10.5353\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7529 - mae: 0.9228 - mse: 1.7529 - val_loss: 10.1352 - val_mae: 2.2462 - val_mse: 10.1352\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7700 - mae: 0.8849 - mse: 1.7700 - val_loss: 10.1191 - val_mae: 2.2202 - val_mse: 10.1191\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6926 - mae: 0.8943 - mse: 1.6926 - val_loss: 10.9243 - val_mae: 2.3963 - val_mse: 10.9243\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5800 - mae: 0.8469 - mse: 1.5800 - val_loss: 10.9779 - val_mae: 2.3036 - val_mse: 10.9779\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7116 - mae: 0.8721 - mse: 1.7116 - val_loss: 9.9597 - val_mae: 2.1814 - val_mse: 9.9597\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6379 - mae: 0.8952 - mse: 1.6379 - val_loss: 10.1449 - val_mae: 2.2329 - val_mse: 10.1449\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6900 - mae: 0.8551 - mse: 1.6900 - val_loss: 11.2831 - val_mae: 2.3686 - val_mse: 11.2831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZSWdzb7UeOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "67f76da6-f1be-4bb4-fe54-eb4e412950cf"
      },
      "source": [
        "loss, mae, mse = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 16.0262 - mae: 2.7799 - mse: 16.0262\n",
            "Testing set Mean Abs Error:  2.78 MPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HKk9r0tUl0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1eadbdff-b526-4ca8-c658-6d2d291d0df8"
      },
      "source": [
        "test_predictions = model.predict(x_test)\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(y_test, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo-fjqokUnN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}